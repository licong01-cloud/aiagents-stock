from deepseek_client import DeepSeekClient
from typing import Dict, Any
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from debug_logger import debug_logger
from datetime import datetime

class StockAnalysisAgents:
    """è‚¡ç¥¨åˆ†æAIæ™ºèƒ½ä½“é›†åˆ"""
    
    def __init__(self, model="deepseek-chat"):
        self.model = model
        self.deepseek_client = DeepSeekClient(model=model)
        
    def technical_analyst_agent(self, stock_info: Dict, stock_data: Any, indicators: Dict) -> Dict[str, Any]:
        """æŠ€æœ¯é¢åˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ” æŠ€æœ¯åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        time.sleep(1)  # æ¨¡æ‹Ÿåˆ†ææ—¶é—´
        
        analysis = self.deepseek_client.technical_analysis(stock_info, stock_data, indicators)
        
        return {
            "agent_name": "æŠ€æœ¯åˆ†æå¸ˆ",
            "agent_role": "è´Ÿè´£æŠ€æœ¯æŒ‡æ ‡åˆ†æã€å›¾è¡¨å½¢æ€è¯†åˆ«ã€è¶‹åŠ¿åˆ¤æ–­",
            "analysis": analysis,
            "focus_areas": ["æŠ€æœ¯æŒ‡æ ‡", "è¶‹åŠ¿åˆ†æ", "æ”¯æ’‘é˜»åŠ›", "äº¤æ˜“ä¿¡å·"],
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def fundamental_analyst_agent(self, stock_info: Dict, financial_data: Dict = None, quarterly_data: Dict = None) -> Dict[str, Any]:
        """åŸºæœ¬é¢åˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ“Š åŸºæœ¬é¢åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        
        # ç±»å‹æ£€æŸ¥å’Œè°ƒè¯•æ—¥å¿—
        if financial_data is not None:
            financial_data_type = type(financial_data).__name__
            debug_logger.debug("fundamental_analyst_agent - financial_dataç±»å‹",
                             type=financial_data_type,
                             is_dict=isinstance(financial_data, dict))
            
            # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œè®°å½•è­¦å‘Š
            if not isinstance(financial_data, dict):
                debug_logger.warning("financial_dataä¸æ˜¯å­—å…¸ç±»å‹",
                                   actual_type=financial_data_type,
                                   expected_type="dict")
                # å¦‚æœfinancial_dataæ˜¯DataFrameæˆ–å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºNoneé¿å…åç»­é”™è¯¯
                financial_data = None
        
        if quarterly_data is not None:
            quarterly_data_type = type(quarterly_data).__name__
            debug_logger.debug("fundamental_analyst_agent - quarterly_dataç±»å‹",
                             type=quarterly_data_type,
                             is_dict=isinstance(quarterly_data, dict))
            
            # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œè®°å½•è­¦å‘Š
            if not isinstance(quarterly_data, dict):
                debug_logger.warning("quarterly_dataä¸æ˜¯å­—å…¸ç±»å‹",
                                   actual_type=quarterly_data_type,
                                   expected_type="dict")
                quarterly_data = None
        
        # å¦‚æœæœ‰å­£æŠ¥æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®æ¥æº
        if quarterly_data is not None and isinstance(quarterly_data, dict) and quarterly_data.get('data_success'):
            income_count = quarterly_data.get('income_statement', {}).get('periods', 0) if quarterly_data.get('income_statement') else 0
            balance_count = quarterly_data.get('balance_sheet', {}).get('periods', 0) if quarterly_data.get('balance_sheet') else 0
            cash_flow_count = quarterly_data.get('cash_flow', {}).get('periods', 0) if quarterly_data.get('cash_flow') else 0
            print(f"   âœ“ å·²è·å–å­£æŠ¥æ•°æ®ï¼šåˆ©æ¶¦è¡¨{income_count}æœŸï¼Œèµ„äº§è´Ÿå€ºè¡¨{balance_count}æœŸï¼Œç°é‡‘æµé‡è¡¨{cash_flow_count}æœŸ")
        else:
            print("   âš  æœªè·å–åˆ°å­£æŠ¥æ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬è´¢åŠ¡æ•°æ®åˆ†æ")
        
        time.sleep(1)
        
        analysis = self.deepseek_client.fundamental_analysis(stock_info, financial_data, quarterly_data)
        
        return {
            "agent_name": "åŸºæœ¬é¢åˆ†æå¸ˆ", 
            "agent_role": "è´Ÿè´£å…¬å¸è´¢åŠ¡åˆ†æã€è¡Œä¸šç ”ç©¶ã€ä¼°å€¼åˆ†æ",
            "analysis": analysis,
            "focus_areas": ["è´¢åŠ¡æŒ‡æ ‡", "è¡Œä¸šåˆ†æ", "å…¬å¸ä»·å€¼", "æˆé•¿æ€§", "å­£æŠ¥è¶‹åŠ¿"],
            "quarterly_data": quarterly_data,  # ä¿å­˜å­£æŠ¥æ•°æ®ä»¥ä¾›åç»­ä½¿ç”¨
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def fund_flow_analyst_agent(self, stock_info: Dict, indicators: Dict, fund_flow_data: Dict = None) -> Dict[str, Any]:
        """èµ„é‡‘é¢åˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ’° èµ„é‡‘é¢åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        
        # å¦‚æœæœ‰èµ„é‡‘æµå‘æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®æ¥æº
        if fund_flow_data and fund_flow_data.get('data_success'):
            print("   âœ“ å·²è·å–èµ„é‡‘æµå‘æ•°æ®ï¼ˆakshareæ•°æ®æºï¼‰")
            if fund_flow_data.get('margin_trading_history'):
                print("   âœ“ å·²è·å–èèµ„èåˆ¸å†å²æ•°æ®ï¼ˆç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—ï¼‰")
        else:
            print("   âš  æœªè·å–åˆ°èµ„é‡‘æµå‘æ•°æ®ï¼Œå°†åŸºäºæŠ€æœ¯æŒ‡æ ‡åˆ†æ")
        
        time.sleep(1)
        
        analysis = self.deepseek_client.fund_flow_analysis(stock_info, indicators, fund_flow_data)
        
        return {
            "agent_name": "èµ„é‡‘é¢åˆ†æå¸ˆ",
            "agent_role": "è´Ÿè´£èµ„é‡‘æµå‘åˆ†æã€ä¸»åŠ›è¡Œä¸ºç ”ç©¶ã€å¸‚åœºæƒ…ç»ªåˆ¤æ–­", 
            "analysis": analysis,
            "focus_areas": ["èµ„é‡‘æµå‘", "ä¸»åŠ›åŠ¨å‘", "å¸‚åœºæƒ…ç»ª", "æµåŠ¨æ€§"],
            "fund_flow_data": fund_flow_data,  # ä¿å­˜èµ„é‡‘æµå‘æ•°æ®ä»¥ä¾›åç»­ä½¿ç”¨
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def risk_management_agent(self, stock_info: Dict, indicators: Dict, risk_data: Dict = None, fund_flow_data: Dict = None) -> Dict[str, Any]:
        """é£é™©ç®¡ç†æ™ºèƒ½ä½“ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("âš ï¸ é£é™©ç®¡ç†å¸ˆæ­£åœ¨è¯„ä¼°ä¸­...")
        
        # å¦‚æœæœ‰é£é™©æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®æ¥æº
        if risk_data and risk_data.get('data_success'):
            print("   âœ“ å·²è·å–ç»Ÿä¸€æ•°æ®æ¥å£é£é™©æ•°æ®ï¼ˆTushareï¼šé™å”®è§£ç¦ã€è‚¡ä¸œå¢å‡æŒã€é‡è¦å…¬å‘Šï¼‰")
        else:
            print("   âš  æœªè·å–åˆ°é£é™©æ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯åˆ†æ")

        if fund_flow_data and fund_flow_data.get('data_success'):
            print("   âœ“ å·²è·å–æµåŠ¨æ€§å‚è€ƒæ•°æ®ï¼ˆç»Ÿä¸€æ•°æ®æ¥å£èµ„é‡‘æµå‘ï¼‰")
        else:
            print("   â„¹ï¸ æœªè·å–åˆ°èµ„é‡‘æµå‘å‚è€ƒæ•°æ®ï¼ŒæµåŠ¨æ€§åˆ†æå°†åŸºäºå…¶ä»–æŒ‡æ ‡")
        
        time.sleep(1)
        
        # æ„å»ºé£é™©æ•°æ®æ–‡æœ¬
        risk_data_text = ""
        if risk_data and risk_data.get('data_success'):
            # ä½¿ç”¨æ ¼å¼åŒ–çš„é£é™©æ•°æ®
            from risk_data_fetcher import RiskDataFetcher
            fetcher = RiskDataFetcher()
            risk_data_text = f"""

ã€å®é™…é£é™©æ•°æ®ã€‘ï¼ˆç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å— / Tushareï¼‰
{fetcher.format_risk_data_for_ai(risk_data)}

ä»¥ä¸Šé£é™©æ•°æ®å·²é€šè¿‡ç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—é¢„å…ˆè·å–ï¼ˆTushareå®˜æ–¹æ¥å£ï¼‰ï¼Œè¯·åŸºäºè¿™äº›å®é™…æ•°æ®è¿›è¡Œæ·±åº¦é£é™©åˆ†æã€‚
"""
        
        liquidity_metrics = risk_data.get('liquidity_metrics') if risk_data else None
        liquidity_text = self._build_liquidity_context(fund_flow_data, liquidity_metrics)

        risk_prompt = f"""
ä½œä¸ºèµ„æ·±é£é™©ç®¡ç†ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œå…¨é¢æ·±åº¦çš„é£é™©è¯„ä¼°ï¼š

è‚¡ç¥¨ä¿¡æ¯ï¼š
- è‚¡ç¥¨ä»£ç ï¼š{stock_info.get('symbol', 'N/A')}
- è‚¡ç¥¨åç§°ï¼š{stock_info.get('name', 'N/A')}
- å½“å‰ä»·æ ¼ï¼š{stock_info.get('current_price', 'N/A')}
- Betaç³»æ•°ï¼š{stock_info.get('beta', 'N/A')}
- 52å‘¨æœ€é«˜ï¼š{stock_info.get('52_week_high', 'N/A')}
- 52å‘¨æœ€ä½ï¼š{stock_info.get('52_week_low', 'N/A')}

æŠ€æœ¯æŒ‡æ ‡ï¼š
- RSIï¼š{indicators.get('rsi', 'N/A')}
- å¸ƒæ—å¸¦ä½ç½®ï¼šå½“å‰ä»·æ ¼ç›¸å¯¹äºä¸Šä¸‹è½¨çš„ä½ç½®
- æ³¢åŠ¨ç‡æŒ‡æ ‡ç­‰
{risk_data_text}
{liquidity_text}

âš ï¸ é‡è¦æç¤ºï¼šä»¥ä¸Šé£é™©æ•°æ®å…¨éƒ¨æ¥è‡ªç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—ï¼ˆTushareå®˜æ–¹æ¥å£ï¼‰ï¼Œè¯·ä½ ï¼š
1. ä»”ç»†è§£ææ¯ä¸€æ¡è®°å½•çš„æ‰€æœ‰å­—æ®µä¿¡æ¯
2. è¯†åˆ«æ•°æ®ä¸­çš„å…³é”®é£é™©ç‚¹ï¼ˆæ—¶é—´ã€è§„æ¨¡ã€é¢‘ç‡ã€è‚¡ä¸œèº«ä»½ç­‰ï¼‰
3. å¯¹æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼Œä¸è¦é—æ¼ä»»ä½•é‡è¦ä¿¡æ¯
4. å¦‚æœæ•°æ®ä¸­æœ‰æ—¥æœŸå­—æ®µï¼Œè¦ç‰¹åˆ«å…³æ³¨æœ€è¿‘çš„è®°å½•å’Œå³å°†å‘ç”Ÿçš„äº‹ä»¶
5. å¦‚æœæ•°æ®ä¸­æœ‰é‡‘é¢/æ¯”ä¾‹å­—æ®µï¼Œè¦è¯„ä¼°å…¶è§„æ¨¡å’Œå½±å“åŠ›
6. åŸºäºå®é™…æ•°æ®ç»™å‡ºé‡åŒ–çš„é£é™©è¯„ä¼°ï¼Œè€Œä¸æ˜¯ç©ºæ³›çš„æè¿°

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œå…¨é¢çš„é£é™©è¯„ä¼°ï¼š

1. **é™å”®è§£ç¦é£é™©åˆ†æ** â­ é‡ç‚¹
   - è§£ç¦æ—¶é—´å’Œè§„æ¨¡è¯„ä¼°
   - è§£ç¦å¯¹è‚¡ä»·çš„æ½œåœ¨å†²å‡»
   - è§£ç¦è‚¡ä¸œç±»å‹åˆ†æï¼ˆåˆ›å§‹äºº/æŠ•èµ„æœºæ„/å…¶ä»–ï¼‰
   - å†å²è§£ç¦åè‚¡ä»·èµ°åŠ¿å‚è€ƒ
   - é£é™©ç­‰çº§è¯„å®šå’Œåº”å¯¹å»ºè®®

2. **è‚¡ä¸œå‡æŒé£é™©åˆ†æ** â­ é‡ç‚¹
   - å‡æŒé¢‘ç‡å’ŒåŠ›åº¦è¯„ä¼°
   - å‡æŒè‚¡ä¸œèº«ä»½å’Œæ„å›¾åˆ†æ
   - å‡æŒå¯¹å¸‚åœºä¿¡å¿ƒçš„å½±å“
   - æ˜¯å¦å­˜åœ¨è¿ç»­å‡æŒæˆ–é›†ä¸­å‡æŒ
   - é£é™©è­¦ç¤ºå’ŒæŠ•èµ„å»ºè®®

3. **é‡è¦äº‹ä»¶é£é™©åˆ†æ** â­ é‡ç‚¹
   - è¯†åˆ«å¯èƒ½å½±å“è‚¡ä»·çš„é‡å¤§äº‹ä»¶
   - äº‹ä»¶æ€§è´¨åˆ¤æ–­ï¼ˆåˆ©å¥½/åˆ©ç©º/ä¸­æ€§ï¼‰
   - äº‹ä»¶å½±å“çš„æ—¶é—´ç»´åº¦ï¼ˆçŸ­æœŸ/ä¸­æœŸ/é•¿æœŸï¼‰
   - äº‹ä»¶çš„ç¡®å®šæ€§å’Œä¸ç¡®å®šæ€§
   - é£é™©æç¤ºå’Œå…³æ³¨è¦ç‚¹

4. **å¸‚åœºé£é™©ï¼ˆç³»ç»Ÿæ€§é£é™©ï¼‰**
   - å®è§‚ç»æµç¯å¢ƒé£é™©
   - å¸‚åœºæ•´ä½“èµ°åŠ¿é£é™©
   - Betaç³»æ•°åæ˜ çš„å¸‚åœºæ•æ„Ÿåº¦
   - ç³»ç»Ÿæ€§é£é™©åº”å¯¹ç­–ç•¥

5. **ä¸ªè‚¡é£é™©ï¼ˆéç³»ç»Ÿæ€§é£é™©ï¼‰**
   - å…¬å¸åŸºæœ¬é¢é£é™©
   - ç»è¥ç®¡ç†é£é™©
   - ç«äº‰åŠ›é£é™©
   - è¡Œä¸šåœ°ä½é£é™©

6. **æµåŠ¨æ€§é£é™©**
   - æˆäº¤é‡å’Œæ¢æ‰‹ç‡åˆ†æ
   - ä¹°å–ç›˜æ·±åº¦è¯„ä¼°
   - æµåŠ¨æ€§æ¯ç«­é£é™©
   - å¤§é¢äº¤æ˜“å½±å“è¯„ä¼°
   - ç»“åˆä»¥ä¸Šèµ„é‡‘æµå‘å‚è€ƒæ•°æ®ï¼Œåˆ¤æ–­ä¸»åŠ›èµ„é‡‘åŠ¨å‘å¯¹æµåŠ¨æ€§çš„å½±å“

7. **æ³¢åŠ¨æ€§é£é™©**
   - ä»·æ ¼æ³¢åŠ¨å¹…åº¦åˆ†æ
   - 52å‘¨æœ€é«˜æœ€ä½ä½åˆ†æ
   - RSIç­‰æŠ€æœ¯æŒ‡æ ‡çš„é£é™©æç¤º
   - æ³¢åŠ¨ç‡å¯¹æŠ•èµ„çš„å½±å“

8. **ä¼°å€¼é£é™©**
   - å½“å‰ä¼°å€¼æ°´å¹³è¯„ä¼°
   - å¸‚åœºé¢„æœŸå’Œä¼°å€¼åå·®
   - ä¼°å€¼è¿‡é«˜é£é™©è­¦ç¤º

9. **è¡Œä¸šé£é™©**
   - è¡Œä¸šå‘¨æœŸé˜¶æ®µ
   - è¡Œä¸šç«äº‰æ ¼å±€
   - è¡Œä¸šæ”¿ç­–é£é™©
   - è¡Œä¸šæŠ€æœ¯å˜é©é£é™©

10. **ç»¼åˆé£é™©è¯„å®š**
    - é£é™©ç­‰çº§è¯„å®šï¼ˆä½/ä¸­/é«˜ï¼‰
    - ä¸»è¦é£é™©å› ç´ æ’åº
    - é£é™©æš´éœ²æ—¶é—´çª—å£
    - é£é™©æ¼”å˜è¶‹åŠ¿åˆ¤æ–­

11. **é£é™©æ§åˆ¶å»ºè®®** â­ æ ¸å¿ƒ
    - ä»“ä½æ§åˆ¶å»ºè®®ï¼ˆå…·ä½“æ¯”ä¾‹ï¼‰
    - æ­¢æŸä½è®¾ç½®å»ºè®®ï¼ˆå…·ä½“ä»·ä½ï¼‰
    - é£é™©è§„é¿ç­–ç•¥ï¼ˆä»€ä¹ˆæƒ…å†µä¸‹ä¸å»ºè®®æŠ•èµ„ï¼‰
    - é£é™©å¯¹å†²æ–¹æ¡ˆï¼ˆå¦‚æœé€‚ç”¨ï¼‰
    - æŒä»“æ—¶é—´å»ºè®®
    - é‡ç‚¹å…³æ³¨æŒ‡æ ‡å’Œä¿¡å·

è¯·åŸºäºå®é™…æ•°æ®è¿›è¡Œå®¢è§‚ã€ä¸“ä¸šã€ä¸¥è°¨çš„é£é™©è¯„ä¼°ï¼Œç»™å‡ºå¯æ“ä½œçš„é£é™©æ§åˆ¶å»ºè®®ã€‚
å¦‚æœæŸäº›é£é™©æ•°æ®ç¼ºå¤±ï¼Œä¹Ÿè¦æŒ‡å‡ºæ•°æ®ç¼ºå¤±æœ¬èº«å¯èƒ½å¸¦æ¥çš„é£é™©ã€‚
"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£é™©ç®¡ç†ä¸“å®¶ï¼Œå…·æœ‰20å¹´ä»¥ä¸Šçš„é£é™©è¯†åˆ«å’Œæ§åˆ¶ç»éªŒï¼Œæ“…é•¿å…¨é¢è¯„ä¼°å„ç±»æŠ•èµ„é£é™©ï¼Œç‰¹åˆ«å…³æ³¨é™å”®è§£ç¦ã€è‚¡ä¸œå‡æŒã€é‡è¦äº‹ä»¶ç­‰å¯èƒ½å½±å“è‚¡ä»·çš„é£é™©å› ç´ ã€‚ä½ æ“…é•¿ä»æµ·é‡åŸå§‹æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œè¿›è¡Œæ·±åº¦è§£æå’Œé‡åŒ–è¯„ä¼°ã€‚"},
            {"role": "user", "content": risk_prompt}
        ]
        
        analysis = self.deepseek_client.call_api(messages, max_tokens=6000)
        
        return {
            "agent_name": "é£é™©ç®¡ç†å¸ˆ",
            "agent_role": "è¯†åˆ«å¹¶è¯„ä¼°å¤šç»´é£é™©ï¼Œæä¾›é£é™©æ§åˆ¶å»ºè®®", 
            "analysis": analysis,
            "focus_areas": ["é™å”®è§£ç¦", "è‚¡ä¸œå‡æŒ", "é‡å¤§äº‹ä»¶", "ç³»ç»Ÿæ€§é£é™©", "æ“ä½œå»ºè®®"],
            "risk_data": risk_data,
            "fund_flow_data": fund_flow_data,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

    def _build_liquidity_context(self, fund_flow_data: Dict[str, Any], liquidity_metrics: Dict[str, Any]) -> str:
        section_title = "\nã€æµåŠ¨æ€§å‚è€ƒæ•°æ®ã€‘"
        lines = [section_title]

        core = None
        if fund_flow_data and fund_flow_data.get('data_success'):
            if isinstance(fund_flow_data, dict):
                core = fund_flow_data.get('fund_flow_data') or fund_flow_data.get('fund_flow')
            if core and isinstance(core, dict):
                records = core.get('data') or core.get('records')
            else:
                records = None
        else:
            records = None

        def parse_date(value):
            if value is None:
                return None
            candidates = ["%Y-%m-%d", "%Y%m%d", "%Y/%m/%d"]
            val = str(value)
            val = val.strip()
            if not val:
                return None
            for fmt in candidates:
                try:
                    return datetime.strptime(val, fmt)
                except Exception:
                    continue
            return None

        def to_float(val):
            if val is None:
                return None
            if isinstance(val, (int, float)):
                return float(val)
            try:
                text = str(val).replace(',', '').replace('%', '').strip()
                if not text:
                    return None
                return float(text)
            except Exception:
                return None

        def pick(item: Dict[str, Any], keys):
            for key in keys:
                if key in item and item[key] not in (None, ""):
                    value = to_float(item[key])
                    if value is not None:
                        return value
            return None

        fund_flow_lines = []
        parsed_records = []
        if records:
            for item in records:
                if not isinstance(item, dict):
                    continue
                dt = None
                for key in ('trade_date', 'æ—¥æœŸ', 'date', 'DAY'):
                    if key in item:
                        dt = parse_date(item[key])
                        if dt:
                            break
                if dt is None:
                    continue
                parsed_records.append((dt, item))

        if parsed_records:
            parsed_records.sort(key=lambda x: x[0], reverse=True)
        
        has_fund_flow = bool(parsed_records)

        def fmt_amount(value):
            if value is None:
                return "N/A"
            if abs(value) >= 1e8:
                return f"{value / 1e8:.2f}äº¿å…ƒ"
            if abs(value) >= 1e4:
                return f"{value / 1e4:.2f}äº¿å…ƒ"
            return f"{value:.2f}ä¸‡å…ƒ"

        def fmt_ratio(value):
            if value is None:
                return "N/A"
            return f"{value:.2f}%"

        if has_fund_flow:
            latest_date, latest_item = parsed_records[0]
            recent_window = parsed_records[:5]

            main_keys = [
                'ä¸»åŠ›å‡€æµå…¥-å‡€é¢(ä¸‡å…ƒ)',
                'ä¸»åŠ›å‡€æµå‡º-å‡€é¢(ä¸‡å…ƒ)',
                'net_amount_main',
                'net_mf_amount',
                'net_amount',
            ]
            total_amount_keys = [
                'æˆäº¤é¢',
                'æˆäº¤é¢(ä¸‡å…ƒ)',
                'æˆäº¤é¢-æ€»é¢(ä¸‡å…ƒ)',
                'amount',
                'total_amount',
            ]
            ratio_keys = [
                'ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”(%)',
                'å‡€æµå…¥å æ¯”(%)',
                'net_mf_rate',
                'net_rate',
            ]

            latest_main = pick(latest_item, main_keys)
            latest_turnover = pick(latest_item, total_amount_keys)
            latest_ratio = pick(latest_item, ratio_keys)

            window_values = [pick(item, main_keys) for _, item in recent_window]
            window_values = [v for v in window_values if v is not None]
            avg_main = sum(window_values) / len(window_values) if window_values else None
            pos_days = sum(1 for v in window_values if v and v > 0)

            min_date = parsed_records[-1][0]
            max_date = parsed_records[0][0]
            source_text = fund_flow_data.get('source') or core.get('source') or 'æœªçŸ¥'

            fund_flow_lines.append(f"èµ„é‡‘æµå‘æ•°æ®æ¥æºï¼š{source_text}ï¼ˆç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—é¢„å…ˆè·å–ï¼‰")
            fund_flow_lines.append(f"è¦†ç›–åŒºé—´ï¼š{min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')}ï¼Œå…± {len(parsed_records)} ä¸ªäº¤æ˜“æ—¥")
            fund_flow_lines.append(
                f"æœ€æ–°äº¤æ˜“æ—¥ {latest_date.strftime('%Y-%m-%d')}ï¼šä¸»åŠ›å‡€æµå…¥ {fmt_amount(latest_main)}ï¼Œæ€»æˆäº¤é¢ {fmt_amount(latest_turnover)}ï¼Œä¸»åŠ›å‡€æµå…¥å æ¯” {fmt_ratio(latest_ratio)}"
            )
            if avg_main is not None:
                fund_flow_lines.append(
                    f"è¿‘5æ—¥ä¸»åŠ›å‡€æµå…¥å‡å€¼ {fmt_amount(avg_main)}ï¼Œå‡€æµå…¥å¤©æ•° {pos_days}/{len(window_values) if window_values else 5}"
                )
            if latest_turnover not in (None, 0) and latest_main not in (None, 0):
                liquidity_ratio = latest_main / latest_turnover * 100
                fund_flow_lines.append(f"ä¸»åŠ›å‡€æµå…¥å æˆäº¤é¢æ¯”é‡çº¦ {fmt_ratio(liquidity_ratio)}")

        if liquidity_metrics and liquidity_metrics.get('has_data'):
            latest_liq = liquidity_metrics.get('latest', {})
            lines.append(
                f"æˆäº¤é‡ä¸æ¢æ‰‹ç‡ï¼ˆTushare daily/daily_basicï¼‰ï¼šæœ€æ–° {latest_liq.get('trade_date', 'N/A')} | "
                f"æ¢æ‰‹ç‡ {fmt_ratio(latest_liq.get('turnover_rate'))} | æˆäº¤é‡ {fmt_amount(latest_liq.get('volume'))}è‚¡ | æˆäº¤é¢ {fmt_amount(latest_liq.get('amount'))}å…ƒ"
            )
            if liquidity_metrics.get('volume_avg_5d') is not None:
                lines.append(
                    f"5æ—¥å¹³å‡æˆäº¤é‡ {fmt_amount(liquidity_metrics.get('volume_avg_5d'))}è‚¡ï¼Œè¾ƒå‰5æ—¥å˜åŒ– {fmt_ratio(liquidity_metrics.get('volume_change_pct_prev'))}"
                )
            lines.append("è¿‘5æ—¥æˆäº¤æ¦‚è§ˆï¼š")
            for rec in liquidity_metrics.get('records', [])[:5]:
                lines.append(
                    f"  - {rec.get('trade_date')} | æ¢æ‰‹ç‡ {fmt_ratio(rec.get('turnover_rate'))} | æˆäº¤é‡ {fmt_amount(rec.get('volume'))}è‚¡ | æ—¥å˜åŠ¨ {fmt_ratio(rec.get('volume_change_pct'))}"
                )
        else:
            lines.append("æœªè·å–åˆ°æ¢æ‰‹ç‡/æˆäº¤é‡æ•°æ®ï¼Œè¯·ç»“åˆå¸‚åœºæˆäº¤ç»Ÿè®¡è¯„ä¼°æµåŠ¨æ€§é£é™©ã€‚")

        if fund_flow_lines:
            lines.append("")
            lines.extend(fund_flow_lines)
        elif not has_fund_flow:
            lines.append("æœªè·å–åˆ°ç»Ÿä¸€æ•°æ®æ¥å£èµ„é‡‘æµå‘æ•°æ®ï¼Œèµ„é‡‘é¢æµåŠ¨æ€§éœ€ç»“åˆå…¶ä»–æŒ‡æ ‡åˆ¤æ–­ã€‚")

        lines.append("è¯·ç»“åˆæˆäº¤é‡ã€æ¢æ‰‹ç‡ä¸ä¸»åŠ›èµ„é‡‘å˜åŒ–ï¼Œè¯„ä¼°æµåŠ¨æ€§é£é™©åŠæ½œåœ¨å‹åŠ›ã€‚")
        lines.append("")

        return "\n".join(lines)
    
    def market_sentiment_agent(self, stock_info: Dict, sentiment_data: Dict = None) -> Dict[str, Any]:
        """å¸‚åœºæƒ…ç»ªåˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ“ˆ å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        
        # å¦‚æœæœ‰å¸‚åœºæƒ…ç»ªæ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®æ¥æº
        if sentiment_data and sentiment_data.get('data_success'):
            print("   âœ“ å·²è·å–å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ˆARBRã€æ¢æ‰‹ç‡ã€æ¶¨è·Œåœç­‰ï¼‰")
        else:
            print("   âš  æœªè·å–åˆ°è¯¦ç»†æƒ…ç»ªæ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯åˆ†æ")
        
        time.sleep(1)
        
        # æ„å»ºå¸¦æœ‰å¸‚åœºæƒ…ç»ªæ•°æ®çš„prompt
        sentiment_data_text = ""
        if sentiment_data and sentiment_data.get('data_success'):
            # ä½¿ç”¨æ ¼å¼åŒ–çš„å¸‚åœºæƒ…ç»ªæ•°æ®
            from market_sentiment_data import MarketSentimentDataFetcher
            fetcher = MarketSentimentDataFetcher()
            sentiment_data_text = f"""

ã€å¸‚åœºæƒ…ç»ªå®é™…æ•°æ®ã€‘
{fetcher.format_sentiment_data_for_ai(sentiment_data)}

ä»¥ä¸Šæ•°æ®æ¥è‡ªç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—ï¼ˆTushareä¼˜å…ˆã€Akshareå¤‡ç”¨ï¼‰ï¼Œè¯·ç»“åˆè¿™äº›å®¢è§‚æ•°æ®è¿›è¡Œåˆ†æã€‚
"""
        
        sentiment_prompt = f"""
ä½œä¸ºå¸‚åœºæƒ…ç»ªåˆ†æä¸“å®¶ï¼Œè¯·åŸºäºå½“å‰å¸‚åœºç¯å¢ƒå’Œå®é™…æ•°æ®å¯¹ä»¥ä¸‹è‚¡ç¥¨è¿›è¡Œæƒ…ç»ªåˆ†æï¼š

è‚¡ç¥¨ä¿¡æ¯ï¼š
- è‚¡ç¥¨ä»£ç ï¼š{stock_info.get('symbol', 'N/A')}
- è‚¡ç¥¨åç§°ï¼š{stock_info.get('name', 'N/A')}
- è¡Œä¸šï¼š{stock_info.get('sector', 'N/A')}
- ç»†åˆ†è¡Œä¸šï¼š{stock_info.get('industry', 'N/A')}
{sentiment_data_text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±åº¦åˆ†æï¼š

1. **ARBRæƒ…ç»ªæŒ‡æ ‡åˆ†æ**
   - è¯¦ç»†è§£è¯»ARå’ŒBRæ•°å€¼çš„å«ä¹‰
   - åˆ†æå½“å‰å¸‚åœºäººæ°”å’ŒæŠ•æœºæ„æ„¿
   - åˆ¤æ–­æ˜¯å¦å­˜åœ¨è¶…ä¹°è¶…å–æƒ…å†µ
   - åŸºäºARBRå†å²ç»Ÿè®¡æ•°æ®è¯„ä¼°å½“å‰ä½ç½®

2. **ä¸ªè‚¡æ´»è·ƒåº¦åˆ†æ**
   - æ¢æ‰‹ç‡åæ˜ çš„èµ„é‡‘æ´»è·ƒç¨‹åº¦
   - ä¸ªè‚¡å…³æ³¨åº¦å’Œè®¨è®ºçƒ­åº¦
   - ä¸å†å²æ°´å¹³å¯¹æ¯”

3. **æ•´ä½“å¸‚åœºæƒ…ç»ª**
   - å¤§ç›˜æ¶¨è·Œæƒ…å†µå¯¹ä¸ªè‚¡çš„å½±å“
   - å¸‚åœºæˆäº¤é‡æ˜¯æ”¾é‡è¿˜æ˜¯ç¼©é‡ï¼Œå¹¶åˆ†ææˆå› 
   - å¸‚åœºæ¶¨è·Œå®¶æ•°ã€æ¶¨è·Œåœæ•°é‡åæ˜ çš„æ•´ä½“æƒ…ç»ª
   - ææ…Œè´ªå©ªæŒ‡æ•°å¸¦æ¥çš„ä¿¡å·

4. **é‡ç‚¹æŒ‡æ•°æŒ‡æ ‡åˆ†æ**
   - ä¸Šè¯ç»¼æŒ‡ã€æ·±è¯æˆæŒ‡ã€ä¸Šè¯50ã€ä¸­è¯500ã€ä¸­å°æ¿æŒ‡ã€åˆ›ä¸šæ¿æŒ‡çš„PE/PBã€æ¢æ‰‹ç‡ã€æ€»å¸‚å€¼è¡¨ç°
   - å¯¹æ¯”å†å²å¹³å‡æ°´å¹³æˆ–ç›¸äº’ä¹‹é—´çš„å·®å¼‚ï¼Œåˆ¤æ–­æŒ‡æ•°ä¼°å€¼æ˜¯å¦åé«˜/åä½
   - æŒ‡å‡ºæŒ‡æ•°æŒ‡æ ‡å¯¹å¸‚åœºé£é™©åå¥½å’Œç»“æ„æ€§æœºä¼šçš„å¯ç¤º

5. **èµ„é‡‘æƒ…ç»ª**
   - èèµ„èåˆ¸æ•°æ®åæ˜ çš„çœ‹å¤šçœ‹ç©ºæƒ…ç»ª
   - ä¸»åŠ›èµ„é‡‘åŠ¨å‘
   - å¸‚åœºæµåŠ¨æ€§çŠ¶å†µ

6. **æƒ…ç»ªå¯¹è‚¡ä»·å½±å“**
   - å½“å‰æƒ…ç»ªå¯¹è‚¡ä»·çš„æ”¯æ’‘æˆ–å‹åˆ¶ä½œç”¨
   - æƒ…ç»ªåè½¬çš„å¯èƒ½æ€§å’Œä¿¡å·
   - çŸ­æœŸæƒ…ç»ªæ³¢åŠ¨é£é™©

7. **æŠ•èµ„å»ºè®®**
   - åŸºäºå¸‚åœºæƒ…ç»ªçš„æ“ä½œå»ºè®®
   - æƒ…ç»ªé¢çš„æœºä¼šå’Œé£é™©æç¤º

è¯·ç¡®ä¿åˆ†æåŸºäºå®é™…æ•°æ®ï¼Œç»™å‡ºå®¢è§‚ä¸“ä¸šçš„å¸‚åœºæƒ…ç»ªè¯„ä¼°ã€‚
"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆï¼Œæ“…é•¿è§£è¯»å¸‚åœºå¿ƒç†å’ŒæŠ•èµ„è€…è¡Œä¸ºï¼Œå–„äºåˆ©ç”¨ARBRç­‰æƒ…ç»ªæŒ‡æ ‡è¿›è¡Œåˆ†æã€‚"},
            {"role": "user", "content": sentiment_prompt}
        ]
        
        analysis = self.deepseek_client.call_api(messages, max_tokens=4000)

        # åœ¨æŠ¥å‘Šå¤´éƒ¨æ‰“å°æœ¬æ¬¡åˆ†æä½¿ç”¨çš„æ•°æ®æ¥æºä¸å…³é”®æ‘˜è¦
        if sentiment_data and sentiment_data.get('data_success'):
            def fmt(value, suffix=""):
                if value is None:
                    return "N/A"
                try:
                    value = float(value)
                except (TypeError, ValueError):
                    return str(value)
                if abs(value) >= 1e12:
                    text = f"{value / 1e12:.2f}ä¸‡äº¿"
                elif abs(value) >= 1e8:
                    text = f"{value / 1e8:.2f}äº¿"
                else:
                    text = f"{value:,.2f}"
                return text + suffix

            def fmt_change(value, suffix=""):
                if value is None:
                    return "æŒå¹³"
                try:
                    value = float(value)
                except (TypeError, ValueError):
                    return str(value)
                if abs(value) < 1e-4:
                    return "æŒå¹³"
                arrow = "â†‘" if value > 0 else "â†“"
                return f"{arrow}{abs(value):.2f}{suffix}"

            header_lines = ["ã€æ•°æ®æ¥æºï¼ˆç»Ÿä¸€æ•°æ®è®¿é—®æ¨¡å—ï¼‰ã€‘"]

            mv = sentiment_data.get('market_volume')
            if mv:
                latest = mv.get('latest', {})
                header_lines.append(
                    f"- å¤§ç›˜æˆäº¤é‡ï¼ˆè¿‘10æ—¥ï¼Œæ¥æºï¼š{mv.get('source', 'tushare')}ï¼‰"
                    f"ï¼š{latest.get('trade_date', 'N/A')} æˆäº¤é¢ {fmt(latest.get('total_amount'), 'äº¿å…ƒ')}ï¼Œ"
                    f"æˆäº¤é‡ {fmt(latest.get('total_volume'), 'äº¿è‚¡')}ï¼Œè¶‹åŠ¿åˆ¤å®šï¼š{mv.get('trend', 'N/A')}"
                )
            metrics = sentiment_data.get('index_daily_metrics', {}).get('indices', {}) if sentiment_data.get('index_daily_metrics') else {}
            if metrics:
                focus_codes = ['000001.SH', '399001.SZ', '000016.SH', '000905.SH', '399005.SZ', '399006.SZ']
                summary_parts = []
                for code in focus_codes:
                    info = metrics.get(code)
                    if not info:
                        continue
                    summary_parts.append(
                        f"{info.get('index_name', code)}({info.get('trade_date', 'N/A')}): "
                        f"PE {fmt(info.get('pe'))}({fmt_change(info.get('pe_change'))}), "
                        f"PB {fmt(info.get('pb'))}({fmt_change(info.get('pb_change'))}), "
                        f"æ¢æ‰‹ç‡ {fmt(info.get('turnover_rate'), '%')}({fmt_change(info.get('turnover_rate_change'), '%')})"
                    )
                if summary_parts:
                    header_lines.append("- æŒ‡æ•°ä¼°å€¼ä¸æ¢æ‰‹ï¼ˆindex_dailybasicï¼‰ï¼š" + "ï¼›".join(summary_parts))

            header_lines.append("- å…¶ä»–æƒ…ç»ªæŒ‡æ ‡ï¼šARBRã€æ¢æ‰‹ç‡ã€æ¶¨è·Œåœã€èèµ„èåˆ¸ã€ææ…Œè´ªå©ªæŒ‡æ•°ç­‰å‡ç”±ç»Ÿä¸€æ¥å£é¢„å…ˆè·å–")

            analysis = "\n".join(header_lines) + "\n\n" + analysis
        
        return {
            "agent_name": "å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆ",
            "agent_role": "è´Ÿè´£å¸‚åœºæƒ…ç»ªç ”ç©¶ã€æŠ•èµ„è€…å¿ƒç†åˆ†æã€çƒ­ç‚¹è¿½è¸ª",
            "analysis": analysis,
            "focus_areas": ["ARBRæŒ‡æ ‡", "å¸‚åœºæƒ…ç»ª", "æŠ•èµ„è€…å¿ƒç†", "èµ„é‡‘æ´»è·ƒåº¦", "ææ…Œè´ªå©ªæŒ‡æ•°"],
            "sentiment_data": sentiment_data,  # ä¿å­˜å¸‚åœºæƒ…ç»ªæ•°æ®ä»¥ä¾›åç»­ä½¿ç”¨
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def news_analyst_agent(self, stock_info: Dict, news_data: Dict = None) -> Dict[str, Any]:
        """æ–°é—»åˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ“° æ–°é—»åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        
        # å¦‚æœæœ‰æ–°é—»æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®æ¥æº
        if news_data and news_data.get('data_success'):
            news_count = news_data.get('news_data', {}).get('count', 0) if news_data.get('news_data') else 0
            source = news_data.get('source', 'unknown')
            print(f"   âœ“ å·²ä» {source} è·å– {news_count} æ¡æ–°é—»")
        else:
            print("   âš  æœªè·å–åˆ°æ–°é—»æ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯åˆ†æ")
        
        time.sleep(1)
        
        # æ„å»ºå¸¦æœ‰æ–°é—»æ•°æ®çš„prompt
        news_text = ""
        if news_data and news_data.get('data_success'):
            # ä½¿ç”¨æ ¼å¼åŒ–çš„æ–°é—»æ•°æ®
            from qstock_news_data import QStockNewsDataFetcher
            fetcher = QStockNewsDataFetcher()
            news_text = f"""

ã€æœ€æ–°æ–°é—»æ•°æ®ã€‘
{fetcher.format_news_for_ai(news_data)}

ä»¥ä¸Šæ˜¯é€šè¿‡qstockè·å–çš„å®é™…æ–°é—»æ•°æ®ï¼Œè¯·é‡ç‚¹åŸºäºè¿™äº›æ•°æ®è¿›è¡Œåˆ†æã€‚
"""
        
        news_prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆï¼Œè¯·åŸºäºæœ€æ–°çš„æ–°é—»å¯¹ä»¥ä¸‹è‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æï¼š

è‚¡ç¥¨ä¿¡æ¯ï¼š
- è‚¡ç¥¨ä»£ç ï¼š{stock_info.get('symbol', 'N/A')}
- è‚¡ç¥¨åç§°ï¼š{stock_info.get('name', 'N/A')}
- è¡Œä¸šï¼š{stock_info.get('sector', 'N/A')}
- ç»†åˆ†è¡Œä¸šï¼š{stock_info.get('industry', 'N/A')}
{news_text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±åº¦åˆ†æï¼š

1. **æ–°é—»æ¦‚è¦**
   - æ¢³ç†æœ€æ–°çš„é‡è¦æ–°é—»
   - æ€»ç»“æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
   - æŒ‰é‡è¦æ€§æ’åºæ–°é—»

2. **æ–°é—»æ€§è´¨åˆ†æ**
   - åˆ†ææ–°é—»çš„æ€§è´¨ï¼ˆåˆ©å¥½/åˆ©ç©º/ä¸­æ€§ï¼‰
   - è¯„ä¼°æ–°é—»çš„å¯ä¿¡åº¦å’Œæƒå¨æ€§
   - è¯†åˆ«æ–°é—»æ¥æºå’Œä¼ æ’­èŒƒå›´

3. **å½±å“è¯„ä¼°**
   - è¯„ä¼°æ–°é—»å¯¹è‚¡ä»·çš„çŸ­æœŸå½±å“
   - åˆ†ææ–°é—»å¯¹å…¬å¸é•¿æœŸå‘å±•çš„å½±å“
   - åˆ¤æ–­æ–°é—»å¯¹è¡Œä¸šçš„å½±å“èŒƒå›´

4. **çƒ­ç‚¹è¯†åˆ«**
   - è¯†åˆ«å¸‚åœºå…³æ³¨çš„çƒ­ç‚¹å’Œç„¦ç‚¹
   - åˆ†æè¯¥è‚¡ç¥¨åœ¨å¸‚åœºä¸­çš„å…³æ³¨åº¦
   - è¯„ä¼°èˆ†è®ºå¯¼å‘å’Œå¸‚åœºæƒ…ç»ª

5. **é‡å¤§äº‹ä»¶è¯†åˆ«**
   - è¯†åˆ«å¯èƒ½å½±å“è‚¡ä»·çš„é‡å¤§äº‹ä»¶
   - è¯„ä¼°äº‹ä»¶çš„ç´§è¿«æ€§å’Œé‡è¦æ€§
   - é¢„åˆ¤åç»­å¯èƒ½çš„å‘å±•å’Œè¿é”ååº”

6. **å¸‚åœºååº”é¢„åˆ¤**
   - é¢„æµ‹å¸‚åœºå¯¹æ–°é—»çš„å¯èƒ½ååº”
   - åˆ¤æ–­æ˜¯å¦å­˜åœ¨é¢„æœŸå·®
   - è¯†åˆ«å¯èƒ½çš„äº¤æ˜“æœºä¼šçª—å£

7. **é£é™©æç¤º**
   - è¯†åˆ«æ–°é—»ä¸­çš„é£é™©ä¿¡å·
   - è¯„ä¼°æ½œåœ¨çš„è´Ÿé¢å½±å“
   - æç¤ºéœ€è¦è­¦æƒ•çš„é£é™©ç‚¹

8. **æŠ•èµ„å»ºè®®**
   - åŸºäºæ–°é—»çš„æ“ä½œå»ºè®®
   - å…³é”®æ—¶é—´èŠ‚ç‚¹å’Œè§‚å¯Ÿç‚¹
   - éœ€è¦æŒç»­å…³æ³¨çš„äº‹é¡¹

è¯·ç¡®ä¿åˆ†æå®¢è§‚ã€ä¸“ä¸šï¼Œé‡ç‚¹å…³æ³¨å¯¹æŠ•èµ„å†³ç­–æœ‰å®è´¨æ€§å½±å“çš„å†…å®¹ã€‚
å¦‚æœæŸäº›æ–°é—»çš„é‡è¦æ€§è¾ƒä½ï¼Œå¯ä»¥ç®€è¦æåŠæˆ–ç•¥è¿‡ã€‚
"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆï¼Œæ“…é•¿è§£è¯»æ–°é—»äº‹ä»¶ã€èˆ†æƒ…åˆ†æï¼Œè¯„ä¼°æ–°é—»å¯¹è‚¡ä»·çš„å½±å“ã€‚ä½ å…·æœ‰æ•é”çš„æ´å¯ŸåŠ›å’Œä¸°å¯Œçš„å¸‚åœºç»éªŒã€‚"},
            {"role": "user", "content": news_prompt}
        ]
        
        analysis = self.deepseek_client.call_api(messages, max_tokens=4000)
        
        return {
            "agent_name": "æ–°é—»åˆ†æå¸ˆ",
            "agent_role": "è´Ÿè´£æ–°é—»äº‹ä»¶åˆ†æã€èˆ†æƒ…ç ”ç©¶ã€é‡å¤§äº‹ä»¶å½±å“è¯„ä¼°",
            "analysis": analysis,
            "focus_areas": ["æ–°é—»è§£è¯»", "èˆ†æƒ…åˆ†æ", "äº‹ä»¶å½±å“", "å¸‚åœºååº”", "æŠ•èµ„æœºä¼š"],
            "news_data": news_data,  # ä¿å­˜æ–°é—»æ•°æ®ä»¥ä¾›åç»­ä½¿ç”¨
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

    def research_report_analyst_agent(self, stock_info: Dict, research_data: Dict = None) -> Dict[str, Any]:
        """æœºæ„ç ”æŠ¥åˆ†ææ™ºèƒ½ä½“"""
        print("ğŸ“‘ æœºæ„ç ”æŠ¥åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")

        # æ„å»ºç ”æŠ¥æ•°æ®æ–‡æœ¬ï¼ˆåŒ…å«å†…å®¹å’Œå†…å®¹åˆ†æï¼‰
        research_text = ""
        content_analysis_text = ""
        
        if research_data and research_data.get('data_success'):
            try:
                items = research_data.get('research_reports', []) or research_data.get('items', []) or research_data.get('reports', [])
                top_items = items[:8]  # å–å‰8æ¡
                lines = []
                for idx, item in enumerate(top_items, 1):
                    title = str(item.get('ç ”æŠ¥æ ‡é¢˜') or item.get('title') or item.get('åç§°') or '')
                    rating = str(item.get('è¯„çº§') or item.get('rating') or '')
                    tp = str(item.get('ç›®æ ‡ä»·') or item.get('target_price') or '')
                    org = str(item.get('æœºæ„åç§°') or item.get('org') or item.get('æœºæ„') or '')
                    date = str(item.get('æ—¥æœŸ') or item.get('date') or item.get('å‘å¸ƒæ—¥æœŸ') or '')
                    content_summary = str(item.get('å†…å®¹æ‘˜è¦') or item.get('content_summary') or '')
                    
                    line = f"{idx}. [{date}] {org} | {title} | è¯„çº§: {rating} | ç›®æ ‡ä»·: {tp}"
                    if content_summary:
                        line += f"\n   å†…å®¹æ‘˜è¦: {content_summary[:200]}..."  # é™åˆ¶æ‘˜è¦é•¿åº¦
                    lines.append(line)
                research_text = "\n".join(lines)
                
                # æ·»åŠ å†…å®¹åˆ†æç»“æœ
                content_analysis = research_data.get('content_analysis', {})
                if content_analysis and content_analysis.get('has_content'):
                    sentiment = content_analysis.get('sentiment_analysis', {})
                    content_analysis_text = f"""
ã€ç ”æŠ¥å†…å®¹åˆ†æã€‘
- åŒ…å«å†…å®¹çš„ç ”æŠ¥æ•°é‡: {content_analysis.get('total_reports_with_content', 0)}
- æ€»å­—ç¬¦æ•°: {content_analysis.get('total_length', 0)}
- å¹³å‡å­—ç¬¦æ•°: {content_analysis.get('avg_length', 0)}
- å…³é”®è¯: {', '.join(content_analysis.get('key_topics', [])[:5])}
- æƒ…æ„Ÿå€¾å‘: {sentiment.get('sentiment', 'N/A')} (å¾—åˆ†: {sentiment.get('sentiment_score', 0)})
- æ­£é¢ä¿¡å·: {sentiment.get('positive_signals', 0)}, è´Ÿé¢ä¿¡å·: {sentiment.get('negative_signals', 0)}
"""
            except Exception as e:
                import traceback
                traceback.print_exc()
                research_text = ""

        prompt = f"""
ä½ æ˜¯ä¸€åæœºæ„ç ”æŠ¥åˆ†æå¸ˆï¼Œè¯·åŸºäºç ”æŠ¥å†…å®¹ä¸åŸºæœ¬ä¿¡æ¯ç»™å‡ºä¸“ä¸šè§£è¯»ï¼š

è‚¡ç¥¨ï¼š{stock_info.get('name','N/A')} ({stock_info.get('symbol','N/A')})
è¡Œä¸šï¼š{stock_info.get('sector','N/A')} / {stock_info.get('industry','N/A')}

ã€æœ€æ–°æœºæ„ç ”æŠ¥æ‘˜è¦ï¼ˆè¿‡å»6ä¸ªæœˆï¼‰ã€‘
{research_text or 'æš‚æ— æœ‰æ•ˆç ”æŠ¥æ•°æ®ï¼Œéœ€åŸºäºåŸºæœ¬ä¿¡æ¯ä¸å¸‚åœºå…±è¯†è¿›è¡Œåˆ†æã€‚'}
{content_analysis_text}

è¯·åŸºäºä»¥ä¸Šç ”æŠ¥å†…å®¹å’Œå†…å®¹åˆ†æç»“æœï¼Œå®Œæˆï¼š
1) è¯„çº§ä¸ç›®æ ‡ä»·çš„åˆ†å¸ƒä¸å˜åŒ–ï¼ˆä¸€è‡´/åˆ†æ­§ç‚¹ï¼‰
2) **ç ”æŠ¥æ ¸å¿ƒè§‚ç‚¹åˆ†æ** â­ é‡ç‚¹ï¼šåŸºäºç ”æŠ¥å†…å®¹æå–çš„æ ¸å¿ƒè§‚ç‚¹ï¼Œåˆ†æå…±æ€§ä¸å·®å¼‚ï¼Œè¯æ®é“¾æ˜¯å¦å……åˆ†
3) **å†…å®¹æƒ…æ„Ÿå€¾å‘è§£è¯»**ï¼šç»“åˆå†…å®¹åˆ†æçš„æƒ…æ„Ÿå¾—åˆ†ï¼Œè¯„ä¼°æœºæ„æ•´ä½“æ€åº¦
4) å¯¹åŸºæœ¬é¢ä¸ä¼°å€¼çš„å½±å“é€»è¾‘ï¼ˆçŸ­/ä¸­æœŸï¼‰
5) è§¦å‘æ¡ä»¶ä¸é£é™©æç¤ºï¼ˆä»ç ”æŠ¥å†…å®¹ä¸­æå–ï¼‰
6) æ“ä½œå»ºè®®ï¼ˆåŸºäºç ”æŠ¥å†…å®¹å’Œä¿¡å·çš„å¯æ‰§è¡Œå»ºè®®ï¼‰

æ³¨æ„ï¼šè¦å……åˆ†ç»“åˆç ”æŠ¥çš„å®é™…å†…å®¹è¿›è¡Œåˆ†æï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–è¯„çº§å’Œç›®æ ‡ä»·ã€‚
"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å–æ–¹ç ”æŠ¥åˆ†æå¸ˆï¼Œå–„äºèšåˆå¤šå®¶æœºæ„è§‚ç‚¹å½¢æˆå¯æ‰§è¡Œç»“è®ºã€‚"},
            {"role": "user", "content": prompt}
        ]

        analysis = self.deepseek_client.call_api(messages, max_tokens=4000)

        return {
            "agent_name": "æœºæ„ç ”æŠ¥åˆ†æå¸ˆ",
            "agent_role": "èšåˆæœºæ„ç ”æŠ¥è§‚ç‚¹ï¼Œåˆ†æè¯„çº§/ç›®æ ‡ä»·ä¸å½±å“è·¯å¾„",
            "analysis": analysis,
            "focus_areas": ["æœºæ„è¯„çº§", "ç›®æ ‡ä»·", "ä¸€è‡´ä¸åˆ†æ­§", "å½±å“è·¯å¾„", "æ“ä½œå»ºè®®"],
            "research_data": research_data,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

    def announcement_analyst_agent(self, stock_info: Dict, announcement_data: Dict = None) -> Dict[str, Any]:
        """å…¬å‘Šåˆ†ææ™ºèƒ½ä½“ - æ·±åº¦åˆ†æä¸Šå¸‚å…¬å¸è¿‘30å¤©å…¬å‘Š"""
        print("ğŸ“¢ å…¬å‘Šåˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")
        
        # ç±»å‹æ£€æŸ¥å’Œè°ƒè¯•æ—¥å¿—
        if announcement_data is not None:
            announcement_data_type = type(announcement_data).__name__
            debug_logger.debug("announcement_analyst_agent - announcement_dataç±»å‹",
                             type=announcement_data_type,
                             is_dict=isinstance(announcement_data, dict))
            
            # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œè®°å½•è­¦å‘Š
            if not isinstance(announcement_data, dict):
                debug_logger.warning("announcement_dataä¸æ˜¯å­—å…¸ç±»å‹",
                                   actual_type=announcement_data_type,
                                   expected_type="dict")
                # è½¬æ¢ä¸ºNoneé¿å…åç»­é”™è¯¯
                announcement_data = None
        else:
            debug_logger.debug("announcement_analyst_agent - announcement_dataä¸ºNone",
                             symbol=stock_info.get('symbol', 'N/A'))

        ann_text = ""
        ann_count = 0
        date_range_str = "N/A"
        pdf_section = ""
        url_section = ""
 
        # å®‰å…¨çš„Noneæ£€æŸ¥å’Œç±»å‹æ£€æŸ¥
        if announcement_data is not None and isinstance(announcement_data, dict) and announcement_data.get('data_success'):
            try:
                # ä½¿ç”¨æ–°çš„æ•°æ®ç»“æ„
                announcements = announcement_data.get('announcements', [])
                ann_count = len(announcements)
 
                # è·å–æ—¶é—´èŒƒå›´
                if announcement_data.get('date_range'):
                    dr = announcement_data['date_range']
                    date_range_str = f"{dr['start']} ~ {dr['end']}"
 
                # è¯¦ç»†æ ¼å¼åŒ–å‰15æ¡å…¬å‘Š
                if announcements:
                    lines = []
                    url_lines = []
                    for idx, ann in enumerate(announcements[:15], 1):
                        date = ann.get('æ—¥æœŸ', 'N/A')
                        title = ann.get('å…¬å‘Šæ ‡é¢˜', 'N/A')
                        ann_type = ann.get('å…¬å‘Šç±»å‹', 'N/A')
                        summary = ann.get('å…¬å‘Šæ‘˜è¦', '')
                        link = ann.get('download_url') or ann.get('pdf_url')
                        origin = ann.get('åŸå§‹æ•°æ®', {}) if isinstance(ann.get('åŸå§‹æ•°æ®'), dict) else {}
                        raw_url = ann.get('download_url') or ann.get('detail_url') or origin.get('url') or origin.get('file_url') or origin.get('adjunct_url')
 
                        line = f"{idx}. [{date}] {title}"
                        if ann_type and ann_type != 'N/A':
                            line += f" (ç±»å‹: {ann_type})"
                        if summary:
                            line += f"\n   æ‘˜è¦: {summary[:100]}{'...' if len(summary) > 100 else ''}"
                        if link and link != 'N/A':
                            line += f"\n   PDFä¸‹è½½: {link}"
                        if raw_url and raw_url != 'N/A':
                            url_lines.append(f"{idx}. {raw_url}")
 
                        lines.append(line)
 
                    ann_text = "\n\n".join(lines)
                    print(f"   âœ“ å°†åˆ†æ {ann_count} æ¡å…¬å‘Š (æ—¶é—´: {date_range_str})")
                    if url_lines:
                        url_section = "\n".join(url_lines)
 
                pdf_analysis = announcement_data.get('pdf_analysis', []) or []
                if pdf_analysis:
                    pdf_lines = []
                    for idx, item in enumerate(pdf_analysis, 1):
                        excerpt = item.get('text') or 'æœªèƒ½è§£æPDFå†…å®¹'
                        if excerpt and len(excerpt) > 500:
                            excerpt = excerpt[:500] + '...'
                        pdf_lines.append(
                            f"{idx}. [{item.get('date', 'N/A')}] {item.get('title', 'N/A')}\n"
                            f"   PDFé“¾æ¥: {item.get('pdf_url', 'N/A')}\n"
                            f"   PDFå†…å®¹æ‘˜å½•: {excerpt}"
                        )
                    pdf_section = "\n".join(pdf_lines)
                    print(f"   âœ“ å·²è·å– {len(pdf_analysis)} ä»½å…¬å‘ŠPDFæ–‡æœ¬ç”¨äºæ·±åº¦åˆ†æ")
            except Exception as e:
                print(f"   âš ï¸ æ ¼å¼åŒ–å…¬å‘Šæ•°æ®å‡ºé”™: {e}")
                ann_text = ""
                pdf_section = ""

        # æ„å»ºåˆ†ææç¤ºè¯
        if ann_text:
            prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±çš„ä¸Šå¸‚å…¬å¸å…¬å‘Šåˆ†æä¸“å®¶ï¼Œç²¾é€šè§£è¯»å„ç±»å…¬å‘Šå¯¹è‚¡ä»·çš„å½±å“ã€‚

ã€è‚¡ç¥¨ä¿¡æ¯ã€‘
è‚¡ç¥¨ï¼š{stock_info.get('name','N/A')} ({stock_info.get('symbol','N/A')})
å½“å‰ä»·æ ¼ï¼š{stock_info.get('current_price','N/A')}

ã€å…¬å‘Šæ•°æ®ã€‘
æ—¶é—´èŒƒå›´ï¼š{date_range_str}
å…¬å‘Šæ•°é‡ï¼š{ann_count} æ¡
æ•°æ®æ¥æºï¼š{announcement_data.get('source', 'N/A') if announcement_data and isinstance(announcement_data, dict) else 'N/A'}

ã€å…¬å‘ŠåŸå§‹é“¾æ¥åˆ—è¡¨ã€‘
{url_section or 'æš‚æ— å¯ç”¨URLï¼Œè¯·æ£€æŸ¥ç»Ÿä¸€æ•°æ®æ¥å£è¾“å‡ºã€‚'}

ã€è¯¦ç»†å…¬å‘Šåˆ—è¡¨ã€‘
{ann_text}

ã€PDFå…¬å‘ŠåŸæ–‡ï¼ˆç»Ÿä¸€æ•°æ®æ¥å£è‡ªåŠ¨ä¸‹è½½ï¼‰ã€‘
{pdf_section if pdf_section else 'æš‚æ— æœ‰æ•ˆPDFæ–‡æœ¬ï¼Œè‹¥éœ€è¯·è‡ªè¡Œä¸‹è½½å…¬å‘ŠæŸ¥çœ‹åŸæ–‡ã€‚'}

è¯·ä½ ä½œä¸ºä¸“ä¸šå…¬å‘Šåˆ†æå¸ˆï¼Œé’ˆå¯¹ä»¥ä¸Šå®é™…å…¬å‘Šè¿›è¡Œæ·±åº¦åˆ†æï¼š

## ä¸€ã€å…¬å‘Šæ•´ä½“è¯„ä¼°
1. å…¬å‘Šæ´»è·ƒåº¦ä¸ä¿¡æ¯æŠ«éœ²è´¨é‡
2. å…¬å‘Šç±»å‹åˆ†å¸ƒä¸é‡ç‚¹å…³æ³¨æ–¹å‘

## äºŒã€é‡å¤§äº‹é¡¹è¯†åˆ« â­æ ¸å¿ƒ
é’ˆå¯¹æ¯æ¡é‡è¦å…¬å‘Šåˆ†æï¼š
- äº‹é¡¹æ€§è´¨ï¼ˆåˆ©å¥½/åˆ©ç©º/ä¸­æ€§ï¼‰åŠå½±å“ç¨‹åº¦
- å¯¹ä¸šç»©ã€ä¼°å€¼ã€å¸‚åœºé¢„æœŸçš„å…·ä½“å½±å“
- æ—¶æ•ˆæ€§ï¼ˆçŸ­æœŸ1-3æœˆ/ä¸­æœŸ3-12æœˆ/é•¿æœŸ1å¹´+ï¼‰

## ä¸‰ã€é£é™©ä¸æœºä¼š
- æ½œåœ¨é£é™©ï¼šä¸šç»©é£é™©ã€è‚¡æƒé£é™©ã€åˆè§„é£é™©ã€ç»è¥é£é™©
- æŠ•èµ„æœºä¼šï¼šä¸šç»©æ”¹å–„ã€é‡å¤§åˆ©å¥½ã€æˆ˜ç•¥è½¬å‹ã€åœ°ä½æå‡

## å››ã€å¸‚åœºååº”é¢„åˆ¤
- å…¬å‘Šå‘å¸ƒåçš„å¯èƒ½å¸‚åœºååº”ï¼ˆç»“åˆPDFåŸæ–‡æ ¸å¿ƒå†…å®¹ï¼‰
- æ˜¯å¦å·²è¢«å……åˆ†æ¶ˆåŒ–
- æ˜¯å¦å­˜åœ¨é¢„æœŸå·®

## äº”ã€æŠ•èµ„å»ºè®®
- çŸ­æœŸæ“ä½œå»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å‡ä»“/å›é¿ï¼‰
- å…³é”®è·Ÿè¸ªäº‹é¡¹ä¸è§¦å‘æ¡ä»¶
- é£é™©æç¤ºä¸æ­¢æŸå»ºè®®

è¯·åŸºäºå®é™…å…¬å‘Šå†…å®¹ç»™å‡ºä¸“ä¸šã€è¯¦ç»†çš„åˆ†æã€‚
"""
        else:
            prompt = f"""
ä½ æ˜¯ä¸€åä¸Šå¸‚å…¬å¸å…¬å‘Šåˆ†æä¸“å®¶ã€‚

è‚¡ç¥¨ï¼š{stock_info.get('name','N/A')} ({stock_info.get('symbol','N/A')})

âš ï¸ å½“å‰æœªè·å–åˆ°è¯¥è‚¡ç¥¨æœ€è¿‘30å¤©çš„å…¬å‘Šæ•°æ®ï¼ˆ{announcement_data.get('error', 'æœªçŸ¥åŸå› ') if announcement_data and isinstance(announcement_data, dict) else 'æ•°æ®è·å–å¤±è´¥'}ï¼‰

è¯·æä¾›ï¼š
1. ä¸Šå¸‚å…¬å¸ä¿¡æ¯æŠ«éœ²çš„é‡è¦æ€§ä¸æŠ•èµ„ä»·å€¼
2. æŠ•èµ„è€…åº”å…³æ³¨çš„å…¬å‘Šç±»å‹ï¼ˆä¸šç»©é¢„å‘Šã€é‡å¤§åˆåŒã€è‚¡æƒå˜åŠ¨ç­‰ï¼‰
3. å¦‚ä½•ä»å…¬å‘Šä¸­è¯†åˆ«æŠ•èµ„æœºä¼šå’Œé£é™©
4. å…¬å‘Šåˆ†æçš„æ–¹æ³•è®ºä¸æ³¨æ„äº‹é¡¹
5. å»ºè®®é€šè¿‡å®˜æ–¹æ¸ é“ï¼ˆäº¤æ˜“æ‰€ç½‘ç«™ï¼‰æŸ¥é˜…å…¬å‘Š

æ³¨æ„ï¼šå› ç¼ºå°‘å®é™…å…¬å‘Šæ•°æ®ï¼Œè¯·æä¾›æ–¹æ³•è®ºæŒ‡å¯¼ï¼Œä¸åšå…·ä½“æŠ•èµ„å»ºè®®ã€‚
"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å…¬å‘Šè§£è¯»åˆ†æå¸ˆï¼Œæ“…é•¿ä»å…¬å‘Šä¸­æŠ½å–å…³é”®ä¿¡æ¯ã€è¯†åˆ«é‡å¤§äº‹é¡¹å¹¶é‡åŒ–å½±å“ã€‚"},
            {"role": "user", "content": prompt}
        ]

        analysis = self.deepseek_client.call_api(messages, max_tokens=4000)

        return {
            "agent_name": "å…¬å‘Šåˆ†æå¸ˆ",
            "agent_role": "æ·±åº¦è§£æä¸Šå¸‚å…¬å¸å…¬å‘Šï¼Œè¯†åˆ«é‡å¤§äº‹é¡¹ï¼Œè¯„ä¼°å½±å“å¹¶ç»™å‡ºæ“ä½œå»ºè®®",
            "analysis": analysis,
            "focus_areas": ["é‡å¤§äº‹é¡¹è¯†åˆ«", "å½±å“è¯„ä¼°", "é£é™©æœºä¼š", "å¸‚åœºååº”", "æ“ä½œå»ºè®®"],
            "announcement_data": announcement_data,
            "announcement_count": ann_count,
            "date_range": date_range_str,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

    def chip_analyst_agent(self, stock_info: Dict, chip_data: Dict = None) -> Dict[str, Any]:
        """ç­¹ç åˆ†ææ™ºèƒ½ä½“ï¼ˆä»…Aè‚¡ï¼‰"""
        print("ğŸ¯ ç­¹ç åˆ†æå¸ˆæ­£åœ¨åˆ†æä¸­...")

        chip_text = ""
        if chip_data and chip_data.get('data_success'):
            try:
                # ä½¿ç”¨æ–°çš„æ•°æ®ç»“æ„ï¼ˆsummaryæˆ–distributionï¼‰
                summary = chip_data.get('summary', {})
                dist = chip_data.get('distribution', {})
                
                # ä¼˜å…ˆä½¿ç”¨summaryï¼ˆæ–°ç»“æ„ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨distributionï¼ˆæ—§ç»“æ„å…¼å®¹ï¼‰
                if summary:
                    focus = []
                    if summary.get('ç­¹ç é›†ä¸­åº¦'):
                        focus.append(f"ç­¹ç é›†ä¸­åº¦: {summary.get('ç­¹ç é›†ä¸­åº¦')}")
                    if summary.get('åŠ æƒå¹³å‡æˆæœ¬'):
                        focus.append(f"åŠ æƒå¹³å‡æˆæœ¬: {summary.get('åŠ æƒå¹³å‡æˆæœ¬')}")
                    if summary.get('æˆæœ¬åŒºé—´'):
                        focus.append(f"æˆæœ¬åŒºé—´: {summary.get('æˆæœ¬åŒºé—´')}")
                    if summary.get('50%æˆæœ¬ï¼ˆä¸­ä½ï¼‰'):
                        focus.append(f"ä¸­ä½æˆæœ¬: {summary.get('50%æˆæœ¬ï¼ˆä¸­ä½ï¼‰')}")
                    if summary.get('5%æˆæœ¬') and summary.get('95%æˆæœ¬'):
                        focus.append(f"æˆæœ¬èŒƒå›´: {summary.get('5%æˆæœ¬')} ~ {summary.get('95%æˆæœ¬')}")
                    if summary.get('å†å²æœ€ä½') and summary.get('å†å²æœ€é«˜'):
                        focus.append(f"å†å²ä»·æ ¼èŒƒå›´: {summary.get('å†å²æœ€ä½')} ~ {summary.get('å†å²æœ€é«˜')}")
                    
                    chip_text = "\n".join(focus) if focus else ""
                elif dist:
                    # å…¼å®¹æ—§æ•°æ®ç»“æ„
                    focus = [
                        f"é›†ä¸­åº¦: {dist.get('concentration','N/A')}",
                        f"ä¸»åŠ›æ§ç›˜: {dist.get('main_control','N/A')}",
                        f"æˆæœ¬åŒºé—´: {dist.get('cost_range','N/A')}",
                    ]
                    chip_text = "\n".join(focus)
                
                # æ·»åŠ 30å¤©ç­¹ç å˜åŒ–åˆ†æ
                change_analysis = chip_data.get('change_analysis') or summary.get('30å¤©å˜åŒ–åˆ†æ')
                if change_analysis:
                    chip_text += "\n\nã€è¿‡å»30å¤©ç­¹ç åˆ†å¸ƒå˜åŒ–åˆ†æã€‘"
                    chip_text += f"\nåˆ†ææœŸé—´: {change_analysis.get('period', 'N/A')} ({change_analysis.get('days_count', 0)}ä¸ªäº¤æ˜“æ—¥)"
                    
                    # ä¸»åŠ›è¡Œä¸ºåˆ¤æ–­
                    main_force = change_analysis.get('main_force_behavior', {})
                    if main_force:
                        chip_text += f"\n\nä¸»åŠ›èµ„é‡‘è¡Œä¸º: {main_force.get('judgment', 'N/A')} (ç½®ä¿¡åº¦: {main_force.get('confidence', 'N/A')})"
                        if main_force.get('description'):
                            chip_text += f"\n{main_force.get('description')}"
                    
                    # ç­¹ç å³°å˜åŒ–
                    peak_analysis = change_analysis.get('chip_peak_analysis', {})
                    if peak_analysis:
                        chip_text += f"\n\nç­¹ç å³°ç§»åŠ¨: {peak_analysis.get('peak_direction', 'N/A')} ({peak_analysis.get('peak_speed', 'N/A')})"
                    
                    # æˆæœ¬å˜åŒ–æ‘˜è¦
                    cost_changes = change_analysis.get('cost_changes', {})
                    if 'weight_avg' in cost_changes:
                        avg_change = cost_changes['weight_avg']
                        chip_text += f"\nåŠ æƒå¹³å‡æˆæœ¬å˜åŒ–: {avg_change['earliest']:.2f} â†’ {avg_change['latest']:.2f} "
                        chip_text += f"({avg_change['change']:+.2f}, {avg_change['change_pct']:+.2f}%)"
                    
                    # é›†ä¸­åº¦å˜åŒ–
                    conc_changes = change_analysis.get('concentration_changes', {})
                    if conc_changes:
                        chip_text += f"\nç­¹ç é›†ä¸­åº¦å˜åŒ–: {conc_changes.get('earliest_level', 'N/A')} â†’ {conc_changes.get('latest_level', 'N/A')} "
                        chip_text += f"({conc_changes.get('trend', 'N/A')})"
                
                # æ·»åŠ æ•°æ®æ¥æºä¿¡æ¯
                if chip_data.get('cyq_perf') or chip_data.get('cyq_chips'):
                    source_info = []
                    if chip_data.get('cyq_perf'):
                        source_info.append(f"cyq_perfæ•°æ®: {chip_data['cyq_perf'].get('count', 0)}æœŸ")
                    if chip_data.get('cyq_chips'):
                        source_info.append(f"cyq_chipsæ•°æ®: {chip_data['cyq_chips'].get('count', 0)}ä¸ªæ•°æ®ç‚¹")
                    if source_info:
                        chip_text += "\n\næ•°æ®æ¥æº: " + " | ".join(source_info)
                        
            except Exception as e:
                debug_logger.warning(f"æ ¼å¼åŒ–ç­¹ç æ•°æ®å¤±è´¥", error=e, symbol=stock_info.get('symbol'))
                chip_text = ""

        prompt = f"""
ä½ æ˜¯ä¸€åç­¹ç ç»“æ„åˆ†æå¸ˆï¼Œè¯·ç»“åˆç­¹ç ä¸é‡ä»·å…³ç³»ç»™å‡ºåˆ¤æ–­ï¼š

è‚¡ç¥¨ï¼š{stock_info.get('name','N/A')} ({stock_info.get('symbol','N/A')})
å½“å‰ä»·æ ¼ï¼š{stock_info.get('current_price', 'N/A')}

ã€ç­¹ç è¦ç‚¹ã€‘
{chip_text or 'æš‚æ— ç­¹ç åˆ†å¸ƒæ•°æ®ï¼Œè¯·ç»“åˆé‡ä»·ä¸æ¢æ‰‹çš„ç»Ÿè®¡ç‰¹å¾è¿›è¡Œæ¨æ–­ã€‚'}

è¯·å®Œæˆï¼š
1) **ç­¹ç é›†ä¸­åº¦ä¸ä¸»åŠ›æ§ç›˜è¯„ä¼°**
   - è¯„ä¼°å½“å‰ç­¹ç é›†ä¸­ç¨‹åº¦
   - åˆ¤æ–­ä¸»åŠ›æ§ç›˜æƒ…å†µ
   - åˆ†æä¸»åŠ›æ“ä½œæ„å›¾

2) **è¿‡å»30å¤©ç­¹ç åˆ†å¸ƒå˜åŒ–åˆ†æ** â­ é‡ç‚¹
   - åˆ†æç­¹ç å³°çš„ç§»åŠ¨æ–¹å‘å’Œé€Ÿåº¦
   - æ ¹æ®ç­¹ç å³°å˜åŒ–åˆ¤æ–­ä¸»åŠ›èµ„é‡‘è¡Œä¸ºï¼š
     * **æ”¶é›†ä½ä»·ç­¹ç **ï¼šä½ä½æˆæœ¬ç¨³å®šã€é›†ä¸­åº¦æå‡ã€å¹³å‡æˆæœ¬ä¸‹é™
     * **è·åˆ©å‡ºé€ƒ**ï¼šé«˜ä½æˆæœ¬å¿«é€Ÿä¸Šå‡ã€ç­¹ç å³°ä¸Šç§»ã€é›†ä¸­åº¦ä¸‹é™
     * **æ´—ç›˜æ•´ç†**ï¼šä½ä½æˆæœ¬ç¨³å®šã€ä¸­ä½æˆæœ¬ä¸Šç§»ã€éœ‡è¡æ•´ç†
     * **æ´¾å‘é˜¶æ®µ**ï¼šé«˜ä½å‡ºç°æ–°ç­¹ç å³°ã€ä½ä½å³°æ¶ˆå¤±
   - è¯„ä¼°ä¸»åŠ›èµ„é‡‘çš„å¸ç­¹/å‡ºè´§å¼ºåº¦
   - è¯†åˆ«ç­¹ç è¿ç§»çš„å…³é”®è½¬æŠ˜ç‚¹

3) **æˆæœ¬åŒºé—´ä¸æ½œåœ¨æ”¯æ’‘/å‹åŠ›å¸¦**
   - è¯†åˆ«å…³é”®æˆæœ¬åŒºé—´ï¼ˆ5%ã€15%ã€50%ã€85%ã€95%æˆæœ¬ä½ï¼‰
   - ç¡®å®šæ”¯æ’‘ä½å’Œå‹åŠ›ä½
   - è¯„ä¼°ä»·æ ¼è¿è¡Œç©ºé—´
   - åˆ†ææˆæœ¬åŒºé—´çš„å˜åŒ–è¶‹åŠ¿

4) **æ¢æ‰‹ä¸é‡ä»·èƒŒç¦»ä¿¡å·**
   - åˆ†ææ¢æ‰‹ç‡ç‰¹å¾
   - è¯†åˆ«é‡ä»·èƒŒç¦»
   - åˆ¤æ–­ç­¹ç è½¬ç§»æ–¹å‘
   - ç»“åˆç­¹ç å˜åŒ–éªŒè¯ä¸»åŠ›è¡Œä¸º

5) **çŸ­/ä¸­æœŸå¯èƒ½çš„ç­¹ç è¿ç§»è·¯å¾„**
   - é¢„æµ‹ç­¹ç æµåŠ¨æ–¹å‘
   - è¯„ä¼°ä»·æ ¼èµ°åŠ¿å¯èƒ½æ€§
   - è¯†åˆ«å…³é”®è½¬æŠ˜ç‚¹
   - é¢„åˆ¤ä¸»åŠ›ä¸‹ä¸€æ­¥æ“ä½œ

6) **æ“ä½œå»ºè®®ï¼ˆä»‹å…¥/æŒæœ‰/å‡ä»“çš„è§¦å‘æ¡ä»¶ä¸ä½ç½®ï¼‰**
   - åŸºäºç­¹ç åˆ†æå’Œä¸»åŠ›è¡Œä¸ºåˆ¤æ–­ï¼Œç»™å‡ºæ˜ç¡®çš„ä¹°å–å»ºè®®
   - è®¾ç½®è§¦å‘æ¡ä»¶
   - ç¡®å®šå…³é”®ä»·ä½
   - æä¾›ä»“ä½ç®¡ç†å»ºè®®

**åˆ†æåŸåˆ™**ï¼š
- ç­¹ç å³°ä¸Šç§» + é«˜ä½æˆæœ¬å¢åŠ  â†’ è­¦æƒ•è·åˆ©å‡ºé€ƒ
- ç­¹ç å³°ä¸‹ç§» + ä½ä½æˆæœ¬ç¨³å®š â†’ å¯èƒ½æ˜¯æ”¶é›†ç­¹ç 
- é›†ä¸­åº¦æå‡ + ä½ä½å¯†é›† â†’ ä¸»åŠ›å¯èƒ½å»ºä»“
- é›†ä¸­åº¦ä¸‹é™ + é«˜ä½å¯†é›† â†’ ä¸»åŠ›å¯èƒ½æ´¾å‘
- ç»“åˆä»·æ ¼ã€æˆäº¤é‡ã€æ¢æ‰‹ç‡ç»¼åˆåˆ¤æ–­
"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„ç­¹ç ç»“æ„åˆ†æå¸ˆï¼Œæ“…é•¿ç»“åˆé‡ä»·ä¸æ¢æ‰‹è¯†åˆ«å…³é”®ä½ç½®ã€‚"},
            {"role": "user", "content": prompt}
        ]

        analysis = self.deepseek_client.call_api(messages, max_tokens=3500)

        return {
            "agent_name": "ç­¹ç åˆ†æå¸ˆ",
            "agent_role": "åˆ†æç­¹ç é›†ä¸­åº¦ã€æˆæœ¬åŒºé—´ã€ä¸»åŠ›æ§ç›˜ä¸å…³é”®ä½ç½®",
            "analysis": analysis,
            "focus_areas": ["ç­¹ç é›†ä¸­åº¦", "ä¸»åŠ›æ§ç›˜", "æˆæœ¬åŒºé—´", "å…³é”®ä½ç½®", "æ“ä½œå»ºè®®"],
            "chip_data": chip_data,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def run_multi_agent_analysis(self, stock_info: Dict, stock_data: Any, indicators: Dict, 
                                 financial_data: Dict = None, fund_flow_data: Dict = None, 
                                 sentiment_data: Dict = None, news_data: Dict = None,
                                 quarterly_data: Dict = None, risk_data: Dict = None,
                                 research_data: Dict = None, announcement_data: Dict = None,
                                 chip_data: Dict = None,
                                 enabled_analysts: Dict = None) -> Dict[str, Any]:
        """è¿è¡Œå¤šæ™ºèƒ½ä½“åˆ†æï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
        
        Args:
            enabled_analysts: å­—å…¸ï¼ŒæŒ‡å®šå“ªäº›åˆ†æå¸ˆå‚ä¸åˆ†æ
                ä¾‹å¦‚: {'technical': True, 'fundamental': True, ...}
                å¦‚æœä¸ºNoneï¼Œåˆ™è¿è¡Œæ‰€æœ‰åˆ†æå¸ˆ
        
        Returns:
            åŒ…å«æ‰€æœ‰åˆ†æç»“æœå’Œæ€§èƒ½ç»Ÿè®¡çš„å­—å…¸
        """
        # è®°å½•æ€»ä½“å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        
        debug_logger.step(1, "å¼€å§‹å¤šæ™ºèƒ½ä½“åˆ†æ", 
                         symbol=stock_info.get('symbol', 'N/A'),
                         stock_name=stock_info.get('name', 'N/A'))
        
        # è®°å½•è¾“å…¥æ•°æ®ä¿¡æ¯
        debug_logger.data_info("stock_info", stock_info)
        debug_logger.data_info("indicators", indicators)
        debug_logger.data_info("financial_data", financial_data)
        debug_logger.data_info("announcement_data", announcement_data)
        
        # å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤æ‰€æœ‰åˆ†æå¸ˆéƒ½å‚ä¸
        if enabled_analysts is None:
            enabled_analysts = {
                'technical': True,
                'fundamental': True,
                'fund_flow': True,
                'risk': True,
                'sentiment': True,
                'news': True,
                'research': True,
                'announcement': True,
                'chip': True
            }
        
        print("ğŸš€ å¯åŠ¨å¤šæ™ºèƒ½ä½“è‚¡ç¥¨åˆ†æç³»ç»Ÿï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰...")
        print("=" * 60)
        
        # æ˜¾ç¤ºå‚ä¸åˆ†æçš„åˆ†æå¸ˆ
        active_analysts = [name for name, enabled in enabled_analysts.items() if enabled]
        print(f"ğŸ“‹ å‚ä¸åˆ†æçš„åˆ†æå¸ˆ: {', '.join(active_analysts)} (å…± {len(active_analysts)} ä½)")
        print("âš¡ åˆ†ææ¨¡å¼: å¹¶è¡Œæ‰§è¡Œï¼ˆå¤šçº¿ç¨‹ï¼‰")
        print("=" * 60)
        
        # å‡†å¤‡åˆ†æä»»åŠ¡
        analysis_tasks = []
        
        # å®šä¹‰åˆ†æä»»åŠ¡å‡½æ•°ï¼ˆå¸¦è®¡æ—¶ï¼‰
        def run_analyst_with_timing(analyst_name, analyst_func, *args):
            """è¿è¡Œå•ä¸ªåˆ†æå¸ˆå¹¶è®°å½•ç”¨æ—¶"""
            start_time = time.time()
            try:
                result = analyst_func(*args)
                elapsed_time = time.time() - start_time
                result['elapsed_time'] = elapsed_time
                return analyst_name, result, elapsed_time, None
            except Exception as e:
                elapsed_time = time.time() - start_time
                print(f"âŒ {analyst_name} åˆ†æå¤±è´¥: {str(e)}")
                return analyst_name, None, elapsed_time, str(e)
        
        # æŠ€æœ¯é¢åˆ†æ
        if enabled_analysts.get('technical', True):
            analysis_tasks.append(('technical', self.technical_analyst_agent, stock_info, stock_data, indicators))
        
        # åŸºæœ¬é¢åˆ†æ
        if enabled_analysts.get('fundamental', True):
            analysis_tasks.append(('fundamental', self.fundamental_analyst_agent, stock_info, financial_data, quarterly_data))
        
        # èµ„é‡‘é¢åˆ†æ
        if enabled_analysts.get('fund_flow', True):
            analysis_tasks.append(('fund_flow', self.fund_flow_analyst_agent, stock_info, indicators, fund_flow_data))
        
        # é£é™©ç®¡ç†åˆ†æ
        if enabled_analysts.get('risk', True):
            analysis_tasks.append(('risk_management', self.risk_management_agent, stock_info, indicators, risk_data, fund_flow_data))
        
        # å¸‚åœºæƒ…ç»ªåˆ†æ
        if enabled_analysts.get('sentiment', False):
            analysis_tasks.append(('market_sentiment', self.market_sentiment_agent, stock_info, sentiment_data))
        
        # æ–°é—»åˆ†æ
        if enabled_analysts.get('news', False):
            analysis_tasks.append(('news', self.news_analyst_agent, stock_info, news_data))

        # æœºæ„ç ”æŠ¥åˆ†æ
        if enabled_analysts.get('research', False):
            analysis_tasks.append(('research_report', self.research_report_analyst_agent, stock_info, research_data))

        # å…¬å‘Šåˆ†æ
        if enabled_analysts.get('announcement', False):
            analysis_tasks.append(('announcement', self.announcement_analyst_agent, stock_info, announcement_data))

        # ç­¹ç åˆ†æ
        if enabled_analysts.get('chip', False):
            analysis_tasks.append(('chip', self.chip_analyst_agent, stock_info, chip_data))
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œåˆ†æ
        agents_results = {}
        timing_results = {}
        lock = threading.Lock()
        
        print(f"\nâ³ å¼€å§‹å¹¶è¡Œåˆ†æ... (å¯åŠ¨ {len(analysis_tasks)} ä¸ªåˆ†æçº¿ç¨‹)")
        print("-" * 60)
        
        with ThreadPoolExecutor(max_workers=len(analysis_tasks)) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = []
            for task in analysis_tasks:
                analyst_name = task[0]
                analyst_func = task[1]
                args = task[2:]
                future = executor.submit(run_analyst_with_timing, analyst_name, analyst_func, *args)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            completed_count = 0
            for future in as_completed(futures):
                analyst_name, result, elapsed_time, error = future.result()
                completed_count += 1
                
                with lock:
                    if result is not None:
                        agents_results[analyst_name] = result
                        timing_results[analyst_name] = elapsed_time
                        print(f"âœ… [{completed_count}/{len(analysis_tasks)}] {result.get('agent_name', analyst_name)} å®Œæˆåˆ†æ (ç”¨æ—¶: {elapsed_time:.2f}ç§’)")
                    else:
                        timing_results[analyst_name] = elapsed_time
                        print(f"âŒ [{completed_count}/{len(analysis_tasks)}] {analyst_name} åˆ†æå¤±è´¥ (ç”¨æ—¶: {elapsed_time:.2f}ç§’) - {error}")
        
        # è®¡ç®—æ€»ç”¨æ—¶
        total_elapsed_time = time.time() - total_start_time
        
        print("-" * 60)
        print(f"âœ… æ‰€æœ‰åˆ†æå¸ˆå®Œæˆåˆ†æ!")
        print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ€»ç”¨æ—¶: {total_elapsed_time:.2f} ç§’")
        print(f"   å¹¶è¡Œæ•ˆç‡: èŠ‚çœäº† {sum(timing_results.values()) - total_elapsed_time:.2f} ç§’")
        print(f"   å¹³å‡å•ä¸ªåˆ†æç”¨æ—¶: {sum(timing_results.values()) / len(timing_results):.2f} ç§’" if timing_results else "")
        
        # æ˜¾ç¤ºå„åˆ†æå¸ˆç”¨æ—¶è¯¦æƒ…
        if timing_results:
            print(f"\nğŸ“Š åˆ†æå¸ˆç”¨æ—¶æ’è¡Œ:")
            sorted_timing = sorted(timing_results.items(), key=lambda x: x[1], reverse=True)
            for idx, (name, elapsed) in enumerate(sorted_timing, 1):
                agent_name = agents_results.get(name, {}).get('agent_name', name)
                print(f"   {idx}. {agent_name}: {elapsed:.2f}ç§’")
        
        print("=" * 60)
        
        # åœ¨ç»“æœä¸­æ·»åŠ æ€§èƒ½ç»Ÿè®¡
        agents_results['_performance'] = {
            'total_time': total_elapsed_time,
            'analyst_times': timing_results,
            'parallel_efficiency': sum(timing_results.values()) - total_elapsed_time if timing_results else 0,
            'analyst_count': len(analysis_tasks)
        }
        
        return agents_results
    
    def conduct_team_discussion(self, agents_results: Dict[str, Any], stock_info: Dict) -> str:
        """è¿›è¡Œå›¢é˜Ÿè®¨è®º"""
        print("ğŸ¤ åˆ†æå›¢é˜Ÿæ­£åœ¨è¿›è¡Œç»¼åˆè®¨è®º...")
        time.sleep(2)
        
        # æ”¶é›†å‚ä¸åˆ†æçš„åˆ†æå¸ˆåå•å’ŒæŠ¥å‘Š
        participants = []
        reports = []
        
        if "technical" in agents_results:
            participants.append("æŠ€æœ¯åˆ†æå¸ˆ")
            reports.append(f"ã€æŠ€æœ¯åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['technical'].get('analysis', '')}")
        
        if "fundamental" in agents_results:
            participants.append("åŸºæœ¬é¢åˆ†æå¸ˆ")
            reports.append(f"ã€åŸºæœ¬é¢åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['fundamental'].get('analysis', '')}")
        
        if "fund_flow" in agents_results:
            participants.append("èµ„é‡‘é¢åˆ†æå¸ˆ")
            reports.append(f"ã€èµ„é‡‘é¢åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['fund_flow'].get('analysis', '')}")
        
        if "risk_management" in agents_results:
            participants.append("é£é™©ç®¡ç†å¸ˆ")
            reports.append(f"ã€é£é™©ç®¡ç†å¸ˆæŠ¥å‘Šã€‘\n{agents_results['risk_management'].get('analysis', '')}")
        
        if "market_sentiment" in agents_results:
            participants.append("å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆ")
            reports.append(f"ã€å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['market_sentiment'].get('analysis', '')}")
        
        if "news" in agents_results:
            participants.append("æ–°é—»åˆ†æå¸ˆ")
            reports.append(f"ã€æ–°é—»åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['news'].get('analysis', '')}")

        if "research_report" in agents_results:
            participants.append("æœºæ„ç ”æŠ¥åˆ†æå¸ˆ")
            reports.append(f"ã€æœºæ„ç ”æŠ¥åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['research_report'].get('analysis', '')}")

        if "announcement" in agents_results:
            participants.append("å…¬å‘Šåˆ†æå¸ˆ")
            reports.append(f"ã€å…¬å‘Šåˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['announcement'].get('analysis', '')}")

        if "chip" in agents_results:
            participants.append("ç­¹ç åˆ†æå¸ˆ")
            reports.append(f"ã€ç­¹ç åˆ†æå¸ˆæŠ¥å‘Šã€‘\n{agents_results['chip'].get('analysis', '')}")
        
        # ç»„åˆæ‰€æœ‰æŠ¥å‘Š
        all_reports = "\n\n".join(reports)
        
        discussion_prompt = f"""
ç°åœ¨è¿›è¡ŒæŠ•èµ„å†³ç­–å›¢é˜Ÿä¼šè®®ï¼Œå‚ä¼šäººå‘˜åŒ…æ‹¬ï¼š{', '.join(participants)}ã€‚

è‚¡ç¥¨ï¼š{stock_info.get('name', 'N/A')} ({stock_info.get('symbol', 'N/A')})

å„åˆ†æå¸ˆæŠ¥å‘Šï¼š

{all_reports}

è¯·æ¨¡æ‹Ÿä¸€åœºçœŸå®çš„æŠ•èµ„å†³ç­–ä¼šè®®è®¨è®ºï¼š
1. å„åˆ†æå¸ˆè§‚ç‚¹çš„ä¸€è‡´æ€§å’Œåˆ†æ­§
2. ä¸åŒç»´åº¦åˆ†æçš„æƒé‡è€ƒé‡
3. é£é™©æ”¶ç›Šè¯„ä¼°
4. æŠ•èµ„æ—¶æœºåˆ¤æ–­
5. ç­–ç•¥åˆ¶å®šæ€è·¯
6. è¾¾æˆåˆæ­¥å…±è¯†

è¯·ä»¥å¯¹è¯å½¢å¼å±•ç°è®¨è®ºè¿‡ç¨‹ï¼Œä½“ç°ä¸“ä¸šå›¢é˜Ÿçš„æ€è¾¨è¿‡ç¨‹ã€‚
æ³¨æ„ï¼šåªè®¨è®ºå‚ä¸åˆ†æçš„åˆ†æå¸ˆçš„è§‚ç‚¹ã€‚
"""
        
        messages = [
            {"role": "system", "content": "ä½ éœ€è¦æ¨¡æ‹Ÿä¸€åœºä¸“ä¸šçš„æŠ•èµ„å›¢é˜Ÿè®¨è®ºä¼šè®®ï¼Œä½“ç°ä¸åŒè§’è‰²çš„è§‚ç‚¹ç¢°æ’å’Œæœ€ç»ˆå…±è¯†å½¢æˆã€‚"},
            {"role": "user", "content": discussion_prompt}
        ]
        
        discussion_result = self.deepseek_client.call_api(messages, max_tokens=6000)
        
        print("âœ… å›¢é˜Ÿè®¨è®ºå®Œæˆ")
        return discussion_result
    
    def make_final_decision(self, discussion_result: str, stock_info: Dict, indicators: Dict) -> Dict[str, Any]:
        """åˆ¶å®šæœ€ç»ˆæŠ•èµ„å†³ç­–"""
        print("ğŸ“‹ æ­£åœ¨åˆ¶å®šæœ€ç»ˆæŠ•èµ„å†³ç­–...")
        time.sleep(1)
        
        decision = self.deepseek_client.final_decision(discussion_result, stock_info, indicators)
        
        print("âœ… æœ€ç»ˆæŠ•èµ„å†³ç­–å®Œæˆ")
        return decision
