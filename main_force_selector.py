#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»åŠ›é€‰è‚¡æ¨¡å—
ä½¿ç”¨pywencaiè·å–ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰100åè‚¡ç¥¨ï¼Œå¹¶è¿›è¡Œæ™ºèƒ½ç­›é€‰
"""

from numpy.ma import minimum_fill_value
import pandas as pd
import pywencai
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import time
import traceback
from debug_logger import debug_logger
from network_optimizer import network_optimizer

class MainForceStockSelector:
    """ä¸»åŠ›é€‰è‚¡ç±»"""
    
    def __init__(self):
        self.raw_data = None
        self.filtered_stocks = None
    
    def get_main_force_stocks(self, start_date: str = None, days_ago: int = None,
                             min_market_cap: float = None, max_market_cap: float = None,
                             market: str = 'all') -> Tuple[bool, pd.DataFrame, str]:
        """
        è·å–ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰100åè‚¡ç¥¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼å¦‚"2025å¹´10æœˆ1æ—¥"ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨days_ago
            days_ago: è·ä»Šå¤šå°‘å¤©
            min_market_cap: æœ€å°å¸‚å€¼é™åˆ¶
            max_market_cap: æœ€å¤§å¸‚å€¼é™åˆ¶
            market: å¸‚åœºé€‰æ‹©ï¼Œ'all'=å…¨éƒ¨, 'asr'=Aè‚¡+ç§‘åˆ›æ¿, 'bse'=åŒ—äº¤æ‰€
            
        Returns:
            (success, dataframe, message)
        """
        try:
            # å¦‚æœæ²¡æœ‰æä¾›å¼€å§‹æ—¥æœŸï¼Œæ ¹æ®days_agoè®¡ç®—
            if not start_date:
                date_obj = datetime.now() - timedelta(days=days_ago)
                start_date = f"{date_obj.year}å¹´{date_obj.month}æœˆ{date_obj.day}æ—¥"
            
            debug_logger.info("ä¸»åŠ›é€‰è‚¡æ•°æ®è·å–å¼€å§‹", 
                            start_date=start_date,
                            days_ago=days_ago,
                            market=market,
                            min_market_cap=min_market_cap,
                            max_market_cap=max_market_cap)
            
            print(f"\n{'='*60}")
            print(f"ğŸ” ä¸»åŠ›é€‰è‚¡ - æ•°æ®è·å–ä¸­")
            print(f"{'='*60}")
            print(f"å¼€å§‹æ—¥æœŸ: {start_date}")
            
            # æ ¹æ®å¸‚åœºé€‰æ‹©ç¡®å®šæŸ¥è¯¢æ¡ä»¶
            market_filter = ""
            market_desc = ""
            if market == 'bse':
                market_filter = "åŒ—äº¤æ‰€ï¼Œ"
                market_desc = "åŒ—äº¤æ‰€è‚¡ç¥¨"
            elif market == 'asr':
                market_filter = ""
                market_desc = "Aè‚¡+ç§‘åˆ›æ¿è‚¡ç¥¨"
            else:
                market_filter = ""
                market_desc = "å…¨éƒ¨è‚¡ç¥¨ï¼ˆAè‚¡+ç§‘åˆ›æ¿+åŒ—äº¤æ‰€ï¼‰"
            
            print(f"ç›®æ ‡: è·å–{market_desc}ä¸»åŠ›èµ„é‡‘å‡€æµå…¥æ’åå‰100åè‚¡ç¥¨")
            debug_logger.info("å¸‚åœºé€‰æ‹©", market=market, market_desc=market_desc, market_filter=market_filter)
            
            # æ„å»ºæŸ¥è¯¢è¯­å¥ - ä½¿ç”¨å¤šä¸ªå¤‡é€‰æ–¹æ¡ˆï¼Œæ‰€æœ‰æ–¹æ¡ˆéƒ½è¦æ±‚è®¡ç®—åŒºé—´æ¶¨è·Œå¹…
            queries = [
                # æ–¹æ¡ˆ1: å®Œæ•´æŸ¥è¯¢ï¼ˆæœ€ä¼˜ï¼‰
                f"{start_date}ä»¥æ¥{market_filter}ä¸»åŠ›èµ„é‡‘å‡€æµå…¥æ’åï¼Œå¹¶è®¡ç®—åŒºé—´æ¶¨è·Œå¹…ï¼Œå¸‚å€¼{min_market_cap}-{max_market_cap}äº¿ä¹‹é—´ï¼Œéstï¼Œ"
                f"æ‰€å±åŒèŠ±é¡ºè¡Œä¸šï¼Œæ€»å¸‚å€¼ï¼Œå‡€åˆ©æ¶¦ï¼Œè¥æ”¶ï¼Œå¸‚ç›ˆç‡ï¼Œå¸‚å‡€ç‡ï¼Œ"
                f"ç›ˆåˆ©èƒ½åŠ›è¯„åˆ†ï¼Œæˆé•¿èƒ½åŠ›è¯„åˆ†ï¼Œè¥è¿èƒ½åŠ›è¯„åˆ†ï¼Œå¿å€ºèƒ½åŠ›è¯„åˆ†ï¼Œ"
                f"ç°é‡‘æµè¯„åˆ†ï¼Œèµ„äº§è´¨é‡è¯„åˆ†ï¼ŒæµåŠ¨æ€§è¯„åˆ†ï¼Œèµ„æœ¬å……è¶³æ€§è¯„åˆ†",
                
                # æ–¹æ¡ˆ2: ç®€åŒ–æŸ¥è¯¢
                f"{start_date}ä»¥æ¥{market_filter}ä¸»åŠ›èµ„é‡‘å‡€æµå…¥ï¼Œå¹¶è®¡ç®—åŒºé—´æ¶¨è·Œå¹…ï¼Œå¸‚å€¼{min_market_cap}-{max_market_cap}äº¿ï¼Œéstï¼Œ"
                f"æ‰€å±åŒèŠ±é¡ºè¡Œä¸šï¼Œæ€»å¸‚å€¼ï¼Œå‡€åˆ©æ¶¦ï¼Œè¥æ”¶ï¼Œå¸‚ç›ˆç‡ï¼Œå¸‚å‡€ç‡",
                
                # æ–¹æ¡ˆ3: åŸºç¡€æŸ¥è¯¢
                f"{start_date}ä»¥æ¥{market_filter}ä¸»åŠ›èµ„é‡‘å‡€æµå…¥æ’åï¼Œå¹¶è®¡ç®—åŒºé—´æ¶¨è·Œå¹…ï¼Œå¸‚å€¼{min_market_cap}-{max_market_cap}äº¿ï¼Œéstï¼Œ"
                f"æ‰€å±è¡Œä¸šï¼Œæ€»å¸‚å€¼",
                
                # æ–¹æ¡ˆ4: æœ€ç®€æŸ¥è¯¢
                f"{start_date}ä»¥æ¥{market_filter}ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰100åï¼Œå¹¶è®¡ç®—åŒºé—´æ¶¨è·Œå¹…ï¼Œå¸‚å€¼{min_market_cap}-{max_market_cap}äº¿ï¼Œéstï¼Œæ‰€å±è¡Œä¸šï¼Œæ€»å¸‚å€¼",
            ]
            
            # å°è¯•ä¸åŒçš„æŸ¥è¯¢æ–¹æ¡ˆ
            query_start_time = time.time()
            all_errors = []  # è®°å½•æ‰€æœ‰é”™è¯¯ä¿¡æ¯
            
            for i, query in enumerate(queries, 1):
                query_attempt_start = time.time()
                debug_logger.info(f"å°è¯•æŸ¥è¯¢æ–¹æ¡ˆ {i}/{len(queries)}", 
                                query_preview=query[:100] + "..." if len(query) > 100 else query,
                                query_length=len(query))
                print(f"\nå°è¯•æ–¹æ¡ˆ {i}/{len(queries)}...")
                print(f"æŸ¥è¯¢è¯­å¥: {query[:100]}...")
                
                try:
                    debug_logger.debug("è°ƒç”¨pywencai.get", query_index=i, query_length=len(query))
                    api_start_time = time.time()
                    result = pywencai.get(query=query, loop=True)
                    api_elapsed = time.time() - api_start_time
                    
                    debug_logger.debug("pywencaiè¿”å›ç»“æœ", 
                                      query_index=i,
                                      result_type=type(result).__name__,
                                      result_is_none=(result is None),
                                      elapsed=f"{api_elapsed:.2f}s")
                    
                    if result is None:
                        error_info = f"æ–¹æ¡ˆ{i}: pywencaiè¿”å›None"
                        debug_logger.warning(error_info, query_index=i, elapsed=f"{api_elapsed:.2f}s")
                        all_errors.append(error_info)
                        print(f"  âš ï¸ æ–¹æ¡ˆ{i}è¿”å›Noneï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ–¹æ¡ˆ")
                        continue
                    
                    # è½¬æ¢ä¸ºDataFrame
                    debug_logger.debug("å¼€å§‹è½¬æ¢DataFrame", query_index=i, result_type=type(result).__name__)
                    df_result = self._convert_to_dataframe(result)
                    
                    if df_result is None:
                        error_info = f"æ–¹æ¡ˆ{i}: DataFrameè½¬æ¢è¿”å›None"
                        debug_logger.warning(error_info, query_index=i, result_type=type(result).__name__)
                        all_errors.append(error_info)
                        print(f"  âš ï¸ æ–¹æ¡ˆ{i}DataFrameè½¬æ¢å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ–¹æ¡ˆ")
                        continue
                    
                    if df_result.empty:
                        error_info = f"æ–¹æ¡ˆ{i}: DataFrameä¸ºç©º"
                        debug_logger.warning(error_info, query_index=i, df_shape="0x0")
                        all_errors.append(error_info)
                        print(f"  âš ï¸ æ–¹æ¡ˆ{i}æ•°æ®ä¸ºç©ºï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ–¹æ¡ˆ")
                        continue
                    
                    # æˆåŠŸè·å–æ•°æ®
                    query_elapsed = time.time() - query_attempt_start
                    debug_logger.info(f"æŸ¥è¯¢æ–¹æ¡ˆ{i}æˆåŠŸ", 
                                    query_index=i,
                                    stock_count=len(df_result),
                                    columns_count=len(df_result.columns),
                                    elapsed=f"{query_elapsed:.2f}s")
                    print(f"  âœ… æ–¹æ¡ˆ{i}æˆåŠŸï¼è·å–åˆ° {len(df_result)} åªè‚¡ç¥¨")
                    self.raw_data = df_result
                    
                    # æ˜¾ç¤ºè·å–åˆ°çš„åˆ—å
                    print(f"\nè·å–åˆ°çš„æ•°æ®å­—æ®µ:")
                    for col in df_result.columns[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå­—æ®µ
                        print(f"  - {col}")
                    if len(df_result.columns) > 15:
                        print(f"  ... è¿˜æœ‰ {len(df_result.columns) - 15} ä¸ªå­—æ®µ")
                    
                    debug_logger.info("ä¸»åŠ›é€‰è‚¡æ•°æ®è·å–æˆåŠŸ",
                                    market=market,
                                    stock_count=len(df_result),
                                    total_elapsed=f"{time.time() - query_start_time:.2f}s")
                    return True, df_result, f"æˆåŠŸè·å–{len(df_result)}åªè‚¡ç¥¨æ•°æ®"
                
                except Exception as e:
                    query_elapsed = time.time() - query_attempt_start
                    error_type = type(e).__name__
                    error_msg = str(e)
                    error_traceback = traceback.format_exc()
                    
                    error_info = f"æ–¹æ¡ˆ{i}: {error_type} - {error_msg}"
                    all_errors.append(error_info)
                    
                    debug_logger.error(f"æŸ¥è¯¢æ–¹æ¡ˆ{i}å¤±è´¥", 
                                     query_index=i,
                                     error_type=error_type,
                                     error_message=error_msg,
                                     elapsed=f"{query_elapsed:.2f}s",
                                     query_preview=query[:100] + "..." if len(query) > 100 else query)
                    
                    debug_logger.debug("é”™è¯¯å †æ ˆè·Ÿè¸ª", 
                                      query_index=i,
                                      traceback=error_traceback)
                    
                    print(f"  âŒ æ–¹æ¡ˆ{i}å¤±è´¥: {error_type} - {error_msg}")
                    print(f"     é”™è¯¯è¯¦æƒ…: {error_msg[:200]}")
                    time.sleep(2)  # å¤±è´¥åç­‰å¾…2ç§’å†è¯•
                    continue
            
            # æ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥
            # å¦‚æœæ˜¯åŒ—äº¤æ‰€ï¼Œå°è¯•ä½¿ç”¨AKShareå¤‡ç”¨æ–¹æ¡ˆ
            if market == 'bse':
                debug_logger.info("pywencaiæ‰€æœ‰æ–¹æ¡ˆå¤±è´¥ï¼Œå°è¯•AKShareå¤‡ç”¨æ–¹æ¡ˆ", market=market)
                print(f"\nâš ï¸ pywencaiæ‰€æœ‰æ–¹æ¡ˆå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨AKShareå¤‡ç”¨æ–¹æ¡ˆè·å–åŒ—äº¤æ‰€è‚¡ç¥¨...")
                
                akshare_result = self._get_bse_stocks_from_akshare(
                    start_date, min_market_cap, max_market_cap
                )
                
                if akshare_result[0]:  # success
                    return akshare_result
            
            total_elapsed = time.time() - query_start_time
            error_msg = "æ‰€æœ‰æŸ¥è¯¢æ–¹æ¡ˆéƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•"
            
            debug_logger.error("ä¸»åŠ›é€‰è‚¡æ•°æ®è·å–å¤±è´¥",
                             market=market,
                             total_queries=len(queries),
                             all_errors=all_errors,
                             total_elapsed=f"{total_elapsed:.2f}s",
                             error_summary="æ‰€æœ‰æŸ¥è¯¢æ–¹æ¡ˆå‡å¤±è´¥")
            
            print(f"\nâŒ {error_msg}")
            print(f"\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            print(f"  æ€»å°è¯•æ¬¡æ•°: {len(queries)}")
            print(f"  æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
            print(f"  å¸‚åœºé€‰æ‹©: {market_desc}")
            print(f"\nå„æ–¹æ¡ˆé”™è¯¯è¯¦æƒ…:")
            for idx, err in enumerate(all_errors, 1):
                print(f"  {idx}. {err}")
            
            return False, None, error_msg
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = f"è·å–ä¸»åŠ›é€‰è‚¡æ•°æ®å¤±è´¥: {str(e)}"
            error_traceback = traceback.format_exc()
            
            debug_logger.error("ä¸»åŠ›é€‰è‚¡æ•°æ®è·å–å¼‚å¸¸",
                             error_type=error_type,
                             error_message=str(e),
                             market=market,
                             start_date=start_date,
                             days_ago=days_ago,
                             traceback=error_traceback)
            
            print(f"\nâŒ {error_msg}")
            print(f"  å¼‚å¸¸ç±»å‹: {error_type}")
            print(f"  å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            return False, None, error_msg
    
    def _convert_to_dataframe(self, result) -> pd.DataFrame:
        """è½¬æ¢é—®è´¢è¿”å›ç»“æœä¸ºDataFrame"""
        try:
            result_type = type(result).__name__
            debug_logger.debug("å¼€å§‹è½¬æ¢DataFrame", result_type=result_type)
            
            if isinstance(result, pd.DataFrame):
                debug_logger.debug("ç»“æœå·²ç»æ˜¯DataFrame", 
                                  shape=f"{result.shape[0]}x{result.shape[1]}",
                                  columns_count=len(result.columns))
                return result
            elif isinstance(result, dict):
                debug_logger.debug("ç»“æœæ˜¯å­—å…¸ç±»å‹", 
                                  dict_keys=list(result.keys())[:10],
                                  dict_size=len(result))
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åµŒå¥—çš„tableV1ç»“æ„
                if 'tableV1' in result:
                    debug_logger.debug("æ‰¾åˆ°tableV1åµŒå¥—ç»“æ„")
                    table_data = result['tableV1']
                    table_data_type = type(table_data).__name__
                    
                    if isinstance(table_data, pd.DataFrame):
                        debug_logger.debug("tableV1æ˜¯DataFrame", 
                                          shape=f"{table_data.shape[0]}x{table_data.shape[1]}")
                        return table_data
                    elif isinstance(table_data, list):
                        debug_logger.debug("tableV1æ˜¯åˆ—è¡¨", list_length=len(table_data))
                        return pd.DataFrame(table_data)
                    else:
                        debug_logger.warning("tableV1ç±»å‹ä¸æ”¯æŒ", table_data_type=table_data_type)
                
                # ç›´æ¥è½¬æ¢å­—å…¸
                debug_logger.debug("ç›´æ¥è½¬æ¢å­—å…¸ä¸ºDataFrame")
                return pd.DataFrame([result])
            elif isinstance(result, list):
                debug_logger.debug("ç»“æœæ˜¯åˆ—è¡¨ç±»å‹", list_length=len(result))
                if len(result) > 0:
                    debug_logger.debug("åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹", first_element_type=type(result[0]).__name__)
                return pd.DataFrame(result)
            else:
                debug_logger.warning("ç»“æœç±»å‹ä¸æ”¯æŒè½¬æ¢", result_type=result_type)
                return None
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            error_traceback = traceback.format_exc()
            
            debug_logger.error("DataFrameè½¬æ¢å¤±è´¥",
                             error_type=error_type,
                             error_message=error_msg,
                             result_type=type(result).__name__ if 'result' in locals() else 'unknown',
                             traceback=error_traceback)
            
            print(f"  è½¬æ¢DataFrameå¤±è´¥: {error_type} - {error_msg}")
            return None
    
    def _get_bse_stocks_from_akshare(self, start_date: str, 
                                      min_market_cap: float = None,
                                      max_market_cap: float = None) -> Tuple[bool, pd.DataFrame, str]:
        """
        ä½¿ç”¨AKShareè·å–åŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        ä»…åœ¨market='bse'ä¸”pywencaiå¤±è´¥æ—¶è°ƒç”¨
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼ˆæ ¼å¼å¦‚"2025å¹´10æœˆ1æ—¥"ï¼‰
            min_market_cap: æœ€å°å¸‚å€¼é™åˆ¶ï¼ˆäº¿å…ƒï¼‰
            max_market_cap: æœ€å¤§å¸‚å€¼é™åˆ¶ï¼ˆäº¿å…ƒï¼‰
            
        Returns:
            (success, dataframe, message)
        """
        try:
            debug_logger.info("å¼€å§‹ä½¿ç”¨AKShareè·å–åŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®", 
                            start_date=start_date,
                            min_market_cap=min_market_cap,
                            max_market_cap=max_market_cap)
            
            import akshare as ak
            
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨stock_bj_a_spot_emï¼ˆåŒ—äº¤æ‰€ä¸“ç”¨å®æ—¶è¡Œæƒ…æ¥å£ï¼‰
            try:
                print(f"  [AKShare] å°è¯•æ–¹æ³•1: stock_bj_a_spot_emï¼ˆåŒ—äº¤æ‰€å®æ—¶è¡Œæƒ…ï¼‰...")
                with network_optimizer.apply():
                    df = ak.stock_bj_a_spot_em()
                
                if df is not None and not df.empty:
                    print(f"  âœ… æ–¹æ³•1æˆåŠŸ: è·å–åˆ° {len(df)} åªåŒ—äº¤æ‰€è‚¡ç¥¨")
                    debug_logger.info("AKShareæ–¹æ³•1æˆåŠŸ", stock_count=len(df))
                    
                    # å¤„ç†æ•°æ®æ ¼å¼ï¼Œä½¿å…¶ä¸pywencaiè¿”å›çš„æ ¼å¼å…¼å®¹
                    df_processed = self._process_akshare_bse_data(df, min_market_cap, max_market_cap)
                    
                    if df_processed is not None and not df_processed.empty:
                        self.raw_data = df_processed
                        return True, df_processed, f"æˆåŠŸè·å–{len(df_processed)}åªåŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®ï¼ˆAKShareï¼‰"
                    
            except Exception as e:
                error_msg = str(e)
                debug_logger.warning("AKShareæ–¹æ³•1å¤±è´¥", error=error_msg)
                print(f"  âš ï¸ æ–¹æ³•1å¤±è´¥: {error_msg[:100]}")
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨stock_zh_a_spot_emå¹¶ç­›é€‰åŒ—äº¤æ‰€è‚¡ç¥¨
            try:
                print(f"  [AKShare] å°è¯•æ–¹æ³•2: stock_zh_a_spot_emï¼ˆåŒ…å«äº¬Aè‚¡ï¼‰...")
                with network_optimizer.apply():
                    df_all = ak.stock_zh_a_spot_em()
                
                if df_all is not None and not df_all.empty:
                    # ç­›é€‰åŒ—äº¤æ‰€è‚¡ç¥¨ï¼ˆä»£ç ä»¥8æˆ–4å¼€å¤´ï¼‰
                    df_bse = df_all[
                        (df_all['ä»£ç '].astype(str).str.startswith('8')) | 
                        (df_all['ä»£ç '].astype(str).str.startswith('4'))
                    ]
                    
                    if not df_bse.empty:
                        print(f"  âœ… æ–¹æ³•2æˆåŠŸ: ç­›é€‰å‡º {len(df_bse)} åªåŒ—äº¤æ‰€è‚¡ç¥¨")
                        debug_logger.info("AKShareæ–¹æ³•2æˆåŠŸ", stock_count=len(df_bse))
                        
                        # å¤„ç†æ•°æ®æ ¼å¼
                        df_processed = self._process_akshare_bse_data(df_bse, min_market_cap, max_market_cap)
                        
                        if df_processed is not None and not df_processed.empty:
                            self.raw_data = df_processed
                            return True, df_processed, f"æˆåŠŸè·å–{len(df_processed)}åªåŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®ï¼ˆAKShareï¼‰"
                    
            except Exception as e:
                error_msg = str(e)
                debug_logger.warning("AKShareæ–¹æ³•2å¤±è´¥", error=error_msg)
                print(f"  âš ï¸ æ–¹æ³•2å¤±è´¥: {error_msg[:100]}")
            
            # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            debug_logger.error("AKShareæ‰€æœ‰æ–¹æ³•å‡å¤±è´¥")
            return False, None, "AKShareå¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥"
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            debug_logger.error("AKShareå¤‡ç”¨æ–¹æ¡ˆå¼‚å¸¸", error_type=error_type, error_message=error_msg)
            return False, None, f"AKShareå¤‡ç”¨æ–¹æ¡ˆå¼‚å¸¸: {error_msg}"
    
    def _process_akshare_bse_data(self, df: pd.DataFrame,
                                   min_market_cap: float = None,
                                   max_market_cap: float = None) -> pd.DataFrame:
        """
        å¤„ç†AKShareè¿”å›çš„åŒ—äº¤æ‰€è‚¡ç¥¨æ•°æ®ï¼Œä½¿å…¶æ ¼å¼ä¸pywencaiå…¼å®¹
        
        Args:
            df: AKShareè¿”å›çš„DataFrame
            min_market_cap: æœ€å°å¸‚å€¼é™åˆ¶ï¼ˆäº¿å…ƒï¼‰
            max_market_cap: æœ€å¤§å¸‚å€¼é™åˆ¶ï¼ˆäº¿å…ƒï¼‰
            
        Returns:
            å¤„ç†åçš„DataFrame
        """
        try:
            if df is None or df.empty:
                return None
            
            # åˆ›å»ºå¤„ç†åçš„DataFrame
            processed_df = df.copy()
            
            # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
            required_cols = ['ä»£ç ', 'åç§°']
            missing_cols = [col for col in required_cols if col not in processed_df.columns]
            if missing_cols:
                debug_logger.warning("AKShareæ•°æ®ç¼ºå°‘å¿…éœ€åˆ—", missing_cols=missing_cols)
                return None
            
            # å¤„ç†å¸‚å€¼åˆ—
            if 'æ€»å¸‚å€¼' not in processed_df.columns:
                if 'å¸‚å€¼' in processed_df.columns:
                    processed_df['æ€»å¸‚å€¼'] = processed_df['å¸‚å€¼']
                elif 'æ€»å¸‚å€¼(å…ƒ)' in processed_df.columns:
                    processed_df['æ€»å¸‚å€¼'] = processed_df['æ€»å¸‚å€¼(å…ƒ)']
                else:
                    # å°è¯•ä»å…¶ä»–åˆ—è®¡ç®—æˆ–è®¾ç½®é»˜è®¤å€¼
                    processed_df['æ€»å¸‚å€¼'] = 0
            
            # å¸‚å€¼ç­›é€‰ï¼ˆè½¬æ¢ä¸ºäº¿å…ƒï¼‰
            if 'æ€»å¸‚å€¼' in processed_df.columns:
                # å‡è®¾AKShareè¿”å›çš„å¸‚å€¼å•ä½æ˜¯å…ƒï¼Œè½¬æ¢ä¸ºäº¿å…ƒ
                if processed_df['æ€»å¸‚å€¼'].max() > 10000:  # å¦‚æœå¤§äº10000ï¼Œå¯èƒ½æ˜¯ä»¥ä¸‡å…ƒä¸ºå•ä½
                    processed_df['æ€»å¸‚å€¼_äº¿å…ƒ'] = processed_df['æ€»å¸‚å€¼'] / 10000
                else:
                    processed_df['æ€»å¸‚å€¼_äº¿å…ƒ'] = processed_df['æ€»å¸‚å€¼'] / 100000000
                
                # åº”ç”¨å¸‚å€¼ç­›é€‰
                if min_market_cap is not None:
                    processed_df = processed_df[processed_df['æ€»å¸‚å€¼_äº¿å…ƒ'] >= min_market_cap]
                if max_market_cap is not None:
                    processed_df = processed_df[processed_df['æ€»å¸‚å€¼_äº¿å…ƒ'] <= max_market_cap]
            
            # æ·»åŠ å¿…è¦çš„ç©ºåˆ—ï¼ˆå¦‚æœpywencaiè¿”å›æ•°æ®ä¸­æœ‰è¿™äº›åˆ—ï¼Œè€ŒAKShareæ²¡æœ‰ï¼‰
            # è¿™æ ·åç»­å¤„ç†ä¸ä¼šå‡ºé”™
            default_cols = {
                'åŒºé—´æ¶¨è·Œå¹…': 0,
                'ä¸»åŠ›èµ„é‡‘å‡€æµå…¥': 0,
                'æ‰€å±è¡Œä¸š': 'åŒ—äº¤æ‰€',
                'æ‰€å±åŒèŠ±é¡ºè¡Œä¸š': 'åŒ—äº¤æ‰€',
                'å‡€åˆ©æ¶¦': None,
                'è¥æ”¶': None,
            }
            
            for col, default_val in default_cols.items():
                if col not in processed_df.columns:
                    processed_df[col] = default_val
            
            debug_logger.info("AKShareæ•°æ®å¤„ç†å®Œæˆ", 
                            original_count=len(df),
                            processed_count=len(processed_df),
                            after_market_cap_filter=len(processed_df))
            
            return processed_df
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            debug_logger.error("å¤„ç†AKShareæ•°æ®å¤±è´¥", error_type=error_type, error_message=error_msg)
            return None
    
    def filter_stocks(self, df: pd.DataFrame, 
                     max_range_change: float = None,
                     min_market_cap: float = None,
                     max_market_cap: float = None) -> pd.DataFrame:
        """
        æ™ºèƒ½ç­›é€‰è‚¡ç¥¨ - åŸºäºæ¶¨è·Œå¹…å’Œå¸‚å€¼
        
        Args:
            df: åŸå§‹è‚¡ç¥¨æ•°æ®DataFrame
            max_range_change: æœ€å¤§æ¶¨è·Œå¹…é™åˆ¶
            min_market_cap: æœ€å°å¸‚å€¼é™åˆ¶
            max_market_cap: æœ€å¤§å¸‚å€¼é™åˆ¶
            
        Returns:
            ç­›é€‰åçš„DataFrame
        """
        if df is None or df.empty:
            return df
        
        print(f"\n{'='*60}")
        print(f"ğŸ” æ™ºèƒ½ç­›é€‰ä¸­...")
        print(f"{'='*60}")
        print(f"ç­›é€‰æ¡ä»¶:")
        print(f"  - åŒºé—´æ¶¨è·Œå¹… < {max_range_change}%")
        print(f"  - å¸‚å€¼èŒƒå›´: {min_market_cap}-{max_market_cap}äº¿")
        
        original_count = len(df)
        filtered_df = df.copy()
        
        # 1. ç­›é€‰åŒºé—´æ¶¨è·Œå¹…ï¼ˆæ™ºèƒ½åŒ¹é…åˆ—åï¼‰
        # ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼ŒæŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾
        interval_pct_col = None
        possible_interval_pct_names = [
            'åŒºé—´æ¶¨è·Œå¹…:å‰å¤æƒ', 
            'åŒºé—´æ¶¨è·Œå¹…:å‰å¤æƒ(%)', 
            'åŒºé—´æ¶¨è·Œå¹…(%)', 
            'åŒºé—´æ¶¨è·Œå¹…', 
            'æ¶¨è·Œå¹…:å‰å¤æƒ', 
            'æ¶¨è·Œå¹…:å‰å¤æƒ(%)',
            'æ¶¨è·Œå¹…(%)',
            'æ¶¨è·Œå¹…'
        ]
        
        # ä¼˜å…ˆç²¾ç¡®åŒ¹é…
        for name in possible_interval_pct_names:
            for col in df.columns:
                if name in col:
                    interval_pct_col = col
                    break
            if interval_pct_col:
                break
        
        if interval_pct_col:
            print(f"\nä½¿ç”¨å­—æ®µ: {interval_pct_col}")
            
            # è½¬æ¢ä¸ºæ•°å€¼å¹¶ç­›é€‰
            filtered_df[interval_pct_col] = pd.to_numeric(filtered_df[interval_pct_col], errors='coerce')
            before = len(filtered_df)
            filtered_df = filtered_df[
                (filtered_df[interval_pct_col].notna()) & 
                (filtered_df[interval_pct_col] < max_range_change)
            ]
            print(f"  åŒºé—´æ¶¨è·Œå¹…ç­›é€‰: {before} -> {len(filtered_df)} åª")
        else:
            print(f"  âš ï¸ æœªæ‰¾åˆ°åŒºé—´æ¶¨è·Œå¹…å­—æ®µï¼Œè·³è¿‡æ¶¨è·Œå¹…ç­›é€‰")
            print(f"  å¯ç”¨å­—æ®µ: {list(df.columns[:10])}")
        
        # 2. ç­›é€‰å¸‚å€¼
        market_cap_cols = [col for col in df.columns if 'æ€»å¸‚å€¼' in col or 'å¸‚å€¼' in col]
        if market_cap_cols:
            col_name = market_cap_cols[0]
            print(f"\nä½¿ç”¨å­—æ®µ: {col_name}")
            
            # è½¬æ¢ä¸ºæ•°å€¼ï¼ˆå•ä½å¯èƒ½æ˜¯äº¿æˆ–å…ƒï¼‰
            filtered_df[col_name] = pd.to_numeric(filtered_df[col_name], errors='coerce')
            
            # åˆ¤æ–­å•ä½ï¼ˆå¦‚æœå€¼å¾ˆå¤§ï¼Œå¯èƒ½æ˜¯å…ƒï¼‰
            max_val = filtered_df[col_name].max()
            if max_val > 100000:  # å¤§äº10ä¸‡ï¼Œè®¤ä¸ºæ˜¯å…ƒ
                print(f"  æ£€æµ‹åˆ°å•ä½ä¸ºå…ƒï¼Œè½¬æ¢ä¸ºäº¿")
                filtered_df[col_name] = filtered_df[col_name] / 100000000
            
            before = len(filtered_df)
            filtered_df = filtered_df[
                (filtered_df[col_name].notna()) & 
                (filtered_df[col_name] >= min_market_cap) &
                (filtered_df[col_name] <= max_market_cap)
            ]
            print(f"  å¸‚å€¼ç­›é€‰: {before} -> {len(filtered_df)} åª")
        
        # 3. å»é™¤STè‚¡ç¥¨ï¼ˆé¢å¤–ä¿é™©ï¼‰
        if 'è‚¡ç¥¨ç®€ç§°' in filtered_df.columns:
            before = len(filtered_df)
            filtered_df = filtered_df[~filtered_df['è‚¡ç¥¨ç®€ç§°'].str.contains('ST', na=False)]
            if before != len(filtered_df):
                print(f"  STè‚¡ç¥¨è¿‡æ»¤: {before} -> {len(filtered_df)} åª")
        
        print(f"\nç­›é€‰å®Œæˆ: {original_count} -> {len(filtered_df)} åªè‚¡ç¥¨")
        
        self.filtered_stocks = filtered_df
        return filtered_df
    
    def get_top_stocks(self, df: pd.DataFrame, top_n: int = None) -> pd.DataFrame:
        """
        è·å–ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰Nåè‚¡ç¥¨
        
        Args:
            df: ç­›é€‰åçš„è‚¡ç¥¨æ•°æ®
            top_n: è¿”å›å‰Nå
            
        Returns:
            å‰Nåè‚¡ç¥¨DataFrame
        """
        if df is None or df.empty:
            return df
        
        # æŸ¥æ‰¾ä¸»åŠ›èµ„é‡‘ç›¸å…³åˆ—ï¼ˆæ™ºèƒ½åŒ¹é…ï¼‰
        main_fund_col = None
        main_fund_patterns = [
            'åŒºé—´ä¸»åŠ›èµ„é‡‘æµå‘',      # å®é™…åˆ—å
            'åŒºé—´ä¸»åŠ›èµ„é‡‘å‡€æµå…¥',
            'ä¸»åŠ›èµ„é‡‘æµå‘',
            'ä¸»åŠ›èµ„é‡‘å‡€æµå…¥',
            'ä¸»åŠ›å‡€æµå…¥'
        ]
        for pattern in main_fund_patterns:
            matching = [col for col in df.columns if pattern in col]
            if matching:
                main_fund_col = matching[0]
                break
        
        if main_fund_col:
            print(f"\nä½¿ç”¨å­—æ®µæ’åº: {main_fund_col}")
            
            # è½¬æ¢ä¸ºæ•°å€¼å¹¶æ’åº
            df[main_fund_col] = pd.to_numeric(df[main_fund_col], errors='coerce')
            top_df = df.nlargest(top_n, main_fund_col)
            
            print(f"è·å–ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰ {len(top_df)} å")
            return top_df
        else:
            # å¦‚æœæ²¡æœ‰ä¸»åŠ›èµ„é‡‘åˆ—ï¼Œç›´æ¥è¿”å›å‰Næ¡
            print(f"æœªæ‰¾åˆ°ä¸»åŠ›èµ„é‡‘åˆ—ï¼Œè¿”å›å‰{top_n}æ¡æ•°æ®")
            return df.head(top_n)
    
    def format_stock_list_for_analysis(self, df: pd.DataFrame) -> List[Dict]:
        """
        æ ¼å¼åŒ–è‚¡ç¥¨åˆ—è¡¨ï¼Œå‡†å¤‡æäº¤ç»™AIåˆ†æå¸ˆ
        
        Args:
            df: è‚¡ç¥¨æ•°æ®DataFrame
            
        Returns:
            æ ¼å¼åŒ–åçš„è‚¡ç¥¨åˆ—è¡¨
        """
        if df is None or df.empty:
            return []
        
        stock_list = []
        
        for idx, row in df.iterrows():
            stock_data = {
                'symbol': row.get('è‚¡ç¥¨ä»£ç ', 'N/A'),
                'name': row.get('è‚¡ç¥¨ç®€ç§°', 'N/A'),
                'industry': row.get('æ‰€å±åŒèŠ±é¡ºè¡Œä¸š', row.get('æ‰€å±è¡Œä¸š', 'N/A')),
                'market_cap': row.get('æ€»å¸‚å€¼[20241209]', row.get('æ€»å¸‚å€¼', 'N/A')),
                'range_change': None,
                'main_fund_inflow': None,
                'pe_ratio': row.get('å¸‚ç›ˆç‡', 'N/A'),
                'pb_ratio': row.get('å¸‚å‡€ç‡', 'N/A'),
                'revenue': row.get('è¥ä¸šæ”¶å…¥', row.get('è¥æ”¶', 'N/A')),
                'net_profit': row.get('å‡€åˆ©æ¶¦', 'N/A'),
                'scores': {},
                'raw_data': row.to_dict()
            }
            
            # æå–åŒºé—´æ¶¨è·Œå¹…ï¼ˆä½¿ç”¨æ™ºèƒ½åŒ¹é…ï¼‰
            interval_pct_col = None
            possible_names = [
                'åŒºé—´æ¶¨è·Œå¹…:å‰å¤æƒ', 'åŒºé—´æ¶¨è·Œå¹…:å‰å¤æƒ(%)', 'åŒºé—´æ¶¨è·Œå¹…(%)', 
                'åŒºé—´æ¶¨è·Œå¹…', 'æ¶¨è·Œå¹…:å‰å¤æƒ', 'æ¶¨è·Œå¹…:å‰å¤æƒ(%)', 'æ¶¨è·Œå¹…(%)', 'æ¶¨è·Œå¹…'
            ]
            for name in possible_names:
                for col in df.columns:
                    if name in col:
                        interval_pct_col = col
                        break
                if interval_pct_col:
                    break
            if interval_pct_col:
                stock_data['range_change'] = row.get(interval_pct_col, 'N/A')
            
            # æå–ä¸»åŠ›èµ„é‡‘ï¼ˆæ™ºèƒ½åŒ¹é…ï¼‰
            main_fund_col = None
            main_fund_patterns = [
                'åŒºé—´ä¸»åŠ›èµ„é‡‘æµå‘', 'åŒºé—´ä¸»åŠ›èµ„é‡‘å‡€æµå…¥', 
                'ä¸»åŠ›èµ„é‡‘æµå‘', 'ä¸»åŠ›èµ„é‡‘å‡€æµå…¥', 'ä¸»åŠ›å‡€æµå…¥'
            ]
            for pattern in main_fund_patterns:
                matching = [col for col in df.columns if pattern in col]
                if matching:
                    main_fund_col = matching[0]
                    break
            if main_fund_col:
                stock_data['main_fund_inflow'] = row.get(main_fund_col, 'N/A')
            
            # æå–è¯„åˆ†
            score_keywords = ['è¯„åˆ†', 'èƒ½åŠ›']
            for col in df.columns:
                if any(keyword in col for keyword in score_keywords):
                    stock_data['scores'][col] = row.get(col, 'N/A')
            
            stock_list.append(stock_data)
        
        return stock_list
    
    def print_stock_summary(self, stock_list: List[Dict]):
        """æ‰“å°è‚¡ç¥¨æ‘˜è¦ä¿¡æ¯"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š å€™é€‰è‚¡ç¥¨åˆ—è¡¨ ({len(stock_list)}åª)")
        print(f"{'='*80}")
        print(f"{'åºå·':<4} {'ä»£ç ':<8} {'åç§°':<12} {'è¡Œä¸š':<15} {'ä¸»åŠ›èµ„é‡‘':<12} {'æ¶¨è·Œå¹…':<8}")
        print(f"{'-'*80}")
        
        for i, stock in enumerate(stock_list, 1):
            symbol = stock['symbol']
            name = stock['name'][:10] if isinstance(stock['name'], str) else 'N/A'
            industry = stock['industry'][:13] if isinstance(stock['industry'], str) else 'N/A'
            
            # æ ¼å¼åŒ–ä¸»åŠ›èµ„é‡‘
            main_fund = stock['main_fund_inflow']
            if isinstance(main_fund, (int, float)):
                if abs(main_fund) >= 100000000:  # å¤§äº1äº¿
                    main_fund_str = f"{main_fund/100000000:.2f}äº¿"
                else:
                    main_fund_str = f"{main_fund/10000:.2f}ä¸‡"
            else:
                main_fund_str = 'N/A'
            
            # æ ¼å¼åŒ–æ¶¨è·Œå¹…
            change = stock['range_change']
            if isinstance(change, (int, float)):
                change_str = f"{change:.2f}%"
            else:
                change_str = 'N/A'
            
            print(f"{i:<4} {symbol:<8} {name:<12} {industry:<15} {main_fund_str:<12} {change_str:<8}")
        
        print(f"{'='*80}\n")

# å…¨å±€å®ä¾‹
main_force_selector = MainForceStockSelector()

