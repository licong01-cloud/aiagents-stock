from __future__ import annotations

from datetime import datetime
from typing import Any, Dict


def generate_longhubang_markdown_report(result_data: Dict[str, Any]) -> str:
    """ç”Ÿæˆé¾™è™æ¦œåˆ†æ Markdown æŠ¥å‘Šã€‚

    è¯¥å®ç°åŸºäºæ—§ç‰ˆ Streamlit ä¸­çš„ generate_markdown_report æŠ½å–ï¼Œ
    ç§»é™¤äº†å¯¹ st çš„ä¾èµ–ï¼Œå¯åœ¨ FastAPI ç­‰æ—  UI ç¯å¢ƒä¸­ç›´æ¥å¤ç”¨ã€‚
    """

    current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")

    # æ ‡é¢˜ä¸æŠ¥å‘Šæ¦‚è§ˆ
    markdown_content = f"""# æ™ºç°é¾™è™æ¦œåˆ†ææŠ¥å‘Š

**AIé©±åŠ¨çš„é¾™è™æ¦œå¤šç»´åº¦åˆ†æç³»ç»Ÿ**

---

## ğŸ“Š æŠ¥å‘Šæ¦‚è§ˆ

- **ç”Ÿæˆæ—¶é—´**: {current_time}
- **æ•°æ®è®°å½•**: {result_data.get('data_info', {}).get('total_records', 0)} æ¡
- **æ¶‰åŠè‚¡ç¥¨**: {result_data.get('data_info', {}).get('total_stocks', 0)} åª
- **æ¶‰åŠæ¸¸èµ„**: {result_data.get('data_info', {}).get('total_youzi', 0)} ä¸ª
- **AIåˆ†æå¸ˆ**: 5ä½ä¸“ä¸šåˆ†æå¸ˆå›¢é˜Ÿ
- **åˆ†ææ¨¡å‹**: DeepSeek AI Multi-Agent System

> âš ï¸ æœ¬æŠ¥å‘Šç”±AIç³»ç»ŸåŸºäºé¾™è™æ¦œå…¬å¼€æ•°æ®è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚

---

## ğŸ“ˆ æ•°æ®æ¦‚å†µ

æœ¬æ¬¡åˆ†æå…±æ¶µç›– **{result_data.get('data_info', {}).get('total_records', 0)}** æ¡é¾™è™æ¦œè®°å½•ï¼Œ
æ¶‰åŠ **{result_data.get('data_info', {}).get('total_stocks', 0)}** åªè‚¡ç¥¨å’Œ 
**{result_data.get('data_info', {}).get('total_youzi', 0)}** ä¸ªæ¸¸èµ„å¸­ä½ã€‚

"""

    # èµ„é‡‘æ¦‚å†µ
    summary = result_data.get("data_info", {}).get("summary", {}) or {}
    markdown_content += f"""
### ğŸ’° èµ„é‡‘æ¦‚å†µ

- **æ€»ä¹°å…¥é‡‘é¢**: {summary.get('total_buy_amount', 0):,.2f} å…ƒ
- **æ€»å–å‡ºé‡‘é¢**: {summary.get('total_sell_amount', 0):,.2f} å…ƒ
- **å‡€æµå…¥é‡‘é¢**: {summary.get('total_net_inflow', 0):,.2f} å…ƒ

"""

    # åˆ†æå…ƒä¿¡æ¯
    data_range = result_data.get("data_date_range")
    meta = result_data.get("analysis_meta") or {}
    mode = meta.get("mode")
    date = meta.get("date")
    days = meta.get("days")

    mode_text = "æœªçŸ¥"
    window_text = ""
    if mode == "date" and date:
        mode_text = "æŒ‡å®šæ—¥æœŸ"
        window_text = f"åˆ†ææ—¥æœŸï¼š{date}"
    elif mode == "recent_days" and days:
        mode_text = "æœ€è¿‘Nå¤©"
        window_text = f"æœ€è¿‘ {days} å¤©æ•°æ®"

    markdown_content += "### ğŸ” åˆ†æå…ƒä¿¡æ¯\n\n"
    markdown_content += f"- **æ•°æ®æ—¥æœŸèŒƒå›´**: {data_range or 'æœªè®°å½•'}\n"
    markdown_content += f"- **åˆ†ææ¨¡å¼**: {mode_text}\n"
    if window_text:
        markdown_content += f"- **åˆ†æçª—å£**: {window_text}\n"
    markdown_content += "\n"

    # æœ€ç»ˆæŠ¥å‘Šæ‘˜è¦
    final_report = result_data.get("final_report", {}) or {}
    final_summary = final_report.get("summary") or ""
    if final_summary:
        markdown_content += "### ğŸ“ æœ€ç»ˆæŠ¥å‘Šæ‘˜è¦\n\n"
        markdown_content += f"{final_summary}\n\n"

    # TOP æ¸¸èµ„
    if summary.get("top_youzi"):
        markdown_content += (
            "### ğŸ† æ´»è·ƒæ¸¸èµ„ TOP10\n\n"
            "| æ’å | æ¸¸èµ„åç§° | å‡€æµå…¥é‡‘é¢(å…ƒ) |\n"
            "|------|----------|---------------|\n"
        )
        for idx, (name, amount) in enumerate(list(summary["top_youzi"].items())[:10], 1):
            markdown_content += f"| {idx} | {name} | {amount:,.2f} |\n"
        markdown_content += "\n"

    # TOP è‚¡ç¥¨
    if summary.get("top_stocks"):
        markdown_content += (
            "### ğŸ“ˆ èµ„é‡‘å‡€æµå…¥ TOP20 è‚¡ç¥¨\n\n"
            "| æ’å | è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | å‡€æµå…¥é‡‘é¢(å…ƒ) |\n"
            "|------|----------|----------|---------------|\n"
        )
        for idx, stock in enumerate(summary["top_stocks"][:20], 1):
            markdown_content += (
                f"| {idx} | {stock['code']} | {stock['name']} | "
                f"{stock['net_inflow']:,.2f} |\n"
            )
        markdown_content += "\n"

    # çƒ­é—¨æ¦‚å¿µ
    if summary.get("hot_concepts"):
        markdown_content += "### ğŸ”¥ çƒ­é—¨æ¦‚å¿µ TOP15\n\n"
        for idx, (concept, count) in enumerate(
            list(summary["hot_concepts"].items())[:15], 1
        ):
            markdown_content += f"{idx}. {concept} ({count}æ¬¡)  \n"
        markdown_content += "\n"

    # AI æ™ºèƒ½è¯„åˆ†æ’å
    scoring = result_data.get("scoring_ranking") or []
    if scoring:
        markdown_content += (
            "## ğŸ† AIæ™ºèƒ½è¯„åˆ†æ’å (TOP10)\n\n"
            "| æ’å | è‚¡ç¥¨åç§° | è‚¡ç¥¨ä»£ç  | ç»¼åˆè¯„åˆ† | èµ„é‡‘å«é‡‘é‡ | å‡€ä¹°å…¥é¢ | å–å‡ºå‹åŠ› | æœºæ„å…±æŒ¯ | åŠ åˆ†é¡¹ | é¡¶çº§æ¸¸èµ„ | ä¹°æ–¹æ•° | æœºæ„å‚ä¸ | å‡€æµå…¥(å…ƒ) |\n"
            "|------|----------|----------|----------|------------|----------|----------|----------|--------|----------|--------|----------|------------|\n"
        )
        for row in scoring[:10]:
            rank = row.get("æ’å") or row.get("rank") or "-"
            name = row.get("è‚¡ç¥¨åç§°") or row.get("name") or "-"
            code = row.get("è‚¡ç¥¨ä»£ç ") or row.get("code") or "-"
            total = row.get("ç»¼åˆè¯„åˆ†") or row.get("score") or "-"
            gold = row.get("èµ„é‡‘å«é‡‘é‡") or "-"
            net_buy = row.get("å‡€ä¹°å…¥é¢") or row.get("net_buy") or "-"
            sell_p = row.get("å–å‡ºå‹åŠ›") or "-"
            inst = row.get("æœºæ„å…±æŒ¯") or "-"
            bonus = row.get("åŠ åˆ†é¡¹") or "-"
            top_yz = row.get("é¡¶çº§æ¸¸èµ„") or "-"
            buyers = row.get("ä¹°æ–¹æ•°") or "-"
            inst_part = row.get("æœºæ„å‚ä¸") or "-"
            net_inflow = row.get("å‡€æµå…¥") or row.get("total_net_inflow") or "-"

            markdown_content += (
                f"| {rank} | {name} | {code} | {total} | {gold} | {net_buy} | {sell_p} | {inst} | {bonus} | "
                f"{top_yz} | {buyers} | {inst_part} | {net_inflow} |\n"
            )
        markdown_content += "\n"

    # æ¨èè‚¡ç¥¨
    recommended = result_data.get("recommended_stocks", []) or []
    if recommended:
        markdown_content += f"""
## ğŸ¯ AIæ¨èè‚¡ç¥¨

åŸºäº5ä½AIåˆ†æå¸ˆçš„ç»¼åˆåˆ†æï¼Œç³»ç»Ÿè¯†åˆ«å‡ºä»¥ä¸‹ **{len(recommended)}** åªæ½œåŠ›è‚¡ç¥¨ï¼Œ
è¿™äº›è‚¡ç¥¨åœ¨èµ„é‡‘æµå‘ã€æ¸¸èµ„å…³æ³¨åº¦ã€é¢˜æçƒ­åº¦ç­‰å¤šä¸ªç»´åº¦è¡¨ç°çªå‡ºã€‚

### æ¨èè‚¡ç¥¨æ¸…å•

| æ’å | è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | å‡€æµå…¥é‡‘é¢ | ç¡®å®šæ€§ | æŒæœ‰å‘¨æœŸ |
|------|----------|----------|------------|--------|----------|
"""
        for stock in recommended[:10]:
            markdown_content += (
                f"| {stock.get('rank', '-')} | {stock.get('code', '-')} | "
                f"{stock.get('name', '-')} | {stock.get('net_inflow', 0):,.0f} | "
                f"{stock.get('confidence', '-')} | {stock.get('hold_period', '-')} |\n"
            )

        markdown_content += "\n### æ¨èç†ç”±è¯¦è§£\n\n"
        for stock in recommended[:5]:  # åªè¯¦ç»†å±•ç¤ºå‰ 5 åª
            markdown_content += (
                f"**{stock.get('rank', '-')}. {stock.get('name', '-')} "
                f"({stock.get('code', '-')})**\n\n"
            )
            markdown_content += f"- æ¨èç†ç”±: {stock.get('reason', 'æš‚æ— ')}\n"
            markdown_content += f"- ç¡®å®šæ€§: {stock.get('confidence', '-')}\n"
            markdown_content += f"- æŒæœ‰å‘¨æœŸ: {stock.get('hold_period', '-')}\n\n"

    # AI åˆ†æå¸ˆæŠ¥å‘Š
    agents_analysis = result_data.get("agents_analysis", {}) or {}
    if agents_analysis:
        markdown_content += "## ğŸ¤– AIåˆ†æå¸ˆæŠ¥å‘Š\n\n"
        markdown_content += "æœ¬æŠ¥å‘Šç”±5ä½AIä¸“ä¸šåˆ†æå¸ˆä»ä¸åŒç»´åº¦è¿›è¡Œåˆ†æï¼Œç»¼åˆå½¢æˆæŠ•èµ„å»ºè®®ï¼š\n\n"
        markdown_content += "- **æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ** - åˆ†ææ¸¸èµ„æ“ä½œç‰¹å¾å’Œæ„å›¾\n"
        markdown_content += "- **ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ** - æŒ–æ˜æ¬¡æ—¥å¤§æ¦‚ç‡ä¸Šæ¶¨çš„è‚¡ç¥¨\n"
        markdown_content += "- **é¢˜æè¿½è¸ªåˆ†æå¸ˆ** - è¯†åˆ«çƒ­ç‚¹é¢˜æå’Œè½®åŠ¨æœºä¼š\n"
        markdown_content += "- **é£é™©æ§åˆ¶ä¸“å®¶** - è¯†åˆ«é«˜é£é™©è‚¡ç¥¨å’Œå¸‚åœºé™·é˜±\n"
        markdown_content += "- **é¦–å¸­ç­–ç•¥å¸ˆ** - ç»¼åˆç ”åˆ¤å¹¶ç»™å‡ºæœ€ç»ˆå»ºè®®\n\n"

        agent_titles = {
            "youzi": "æ¸¸èµ„è¡Œä¸ºåˆ†æå¸ˆ",
            "stock": "ä¸ªè‚¡æ½œåŠ›åˆ†æå¸ˆ",
            "theme": "é¢˜æè¿½è¸ªåˆ†æå¸ˆ",
            "risk": "é£é™©æ§åˆ¶ä¸“å®¶",
            "chief": "é¦–å¸­ç­–ç•¥å¸ˆç»¼åˆç ”åˆ¤",
        }

        for agent_key, agent_title in agent_titles.items():
            agent_data = agents_analysis.get(agent_key, {}) or {}
            if agent_data:
                markdown_content += f"### {agent_title}\n\n"
                analysis_text = agent_data.get("analysis", "æš‚æ— åˆ†æ")
                analysis_text = analysis_text.replace("\n", "\n\n")
                markdown_content += f"{analysis_text}\n\n"

    markdown_content += """
---

*æŠ¥å‘Šç”±æ™ºç°é¾™è™AIç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

    return markdown_content
